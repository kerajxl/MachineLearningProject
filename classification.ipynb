{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd \n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime as dt \n",
    "import warnings\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score, precision_score, roc_auc_score, recall_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 21 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              1500 non-null   object \n",
      " 1   age                             1500 non-null   object \n",
      " 2   gender                          1500 non-null   object \n",
      " 3   education                       1500 non-null   object \n",
      " 4   country                         1500 non-null   object \n",
      " 5   ethnicity                       1500 non-null   object \n",
      " 6   personality_neuroticism         1500 non-null   float64\n",
      " 7   personality_extraversion        1500 non-null   float64\n",
      " 8   personality_openness            1500 non-null   float64\n",
      " 9   personality_agreeableness       1500 non-null   float64\n",
      " 10  personality_conscientiousness   1500 non-null   float64\n",
      " 11  personality_impulsiveness       1500 non-null   float64\n",
      " 12  personality_sensation           1500 non-null   float64\n",
      " 13  consumption_alcohol             1500 non-null   object \n",
      " 14  consumption_amphetamines        1500 non-null   object \n",
      " 15  consumption_caffeine            1500 non-null   object \n",
      " 16  consumption_cannabis            1500 non-null   object \n",
      " 17  consumption_chocolate           1500 non-null   object \n",
      " 18  consumption_mushrooms           1500 non-null   object \n",
      " 19  consumption_nicotine            1500 non-null   object \n",
      " 20  consumption_cocaine_last_month  1500 non-null   object \n",
      "dtypes: float64(7), object(14)\n",
      "memory usage: 246.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'gender', 'education', 'country', 'ethnicity',\n",
       "       'personality_neuroticism', 'personality_extraversion',\n",
       "       'personality_openness', 'personality_agreeableness',\n",
       "       'personality_conscientiousness', 'personality_impulsiveness',\n",
       "       'personality_sensation', 'consumption_alcohol',\n",
       "       'consumption_amphetamines', 'consumption_caffeine',\n",
       "       'consumption_cannabis', 'consumption_chocolate',\n",
       "       'consumption_mushrooms', 'consumption_nicotine',\n",
       "       'consumption_cocaine_last_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs = pd.read_csv('drugs_train.csv')\n",
    "drugs.info()\n",
    "drugs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Some college or university, no certificate or degree    405\n",
       "University degree                                       376\n",
       "Masters degree                                          229\n",
       "Professional certificate/ diploma                       221\n",
       "Left school at 18 years                                  85\n",
       "Left school at 16 years                                  72\n",
       "Doctorate degree                                         66\n",
       "Left school at 17 years                                  26\n",
       "Left school before 16 years                              20\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(drugs.describe())\n",
    "def getting_dummies(drugs):\n",
    "    drugs['tmp'] = range(0,drugs.shape[0])\n",
    "    t1 = pd.get_dummies(drugs['age'])\n",
    "    t1['tmp'] = range(0,drugs.shape[0])\n",
    "    drugs = pd.merge(drugs, t1, on = ['tmp'])\n",
    "\n",
    "    t1 = pd.get_dummies(drugs['country'])\n",
    "    t1['tmp'] = range(0,drugs.shape[0])\n",
    "    drugs = pd.merge(drugs, t1, on = ['tmp'])\n",
    "    drugs['Other_country'] = drugs['Other'] + drugs['Ireland'] + drugs['Canada']\n",
    "\n",
    "    t1 = pd.get_dummies(drugs['ethnicity'])\n",
    "    t1['tmp'] = range(0,drugs.shape[0])\n",
    "    drugs = pd.merge(drugs, t1, on = ['tmp'])\n",
    "\n",
    "    drugs = drugs.drop(columns = ['tmp', 'age', 'country', 'ethnicity','Ireland', 'Canada', 'Other_x' ])\n",
    "\n",
    "    return (drugs)\n",
    "\n",
    "def getting_ordinals(drugs):\n",
    "    \n",
    "    lst = ['consumption_alcohol', 'consumption_amphetamines', 'consumption_caffeine',\n",
    "            'consumption_cannabis', 'consumption_chocolate',\n",
    "            'consumption_mushrooms', 'consumption_nicotine']\n",
    "    consDict = {'never used':0,  'used over a decade ago':1,\n",
    "       'used in last decade':2,'used in last year':3, 'used in last month':4, 'used in last week' : 5, 'used in last day' : 6}\n",
    "\n",
    "    eduDict = {'Left school before 16 years' : 0, 'Left school at 16 years' : 0, 'Left school at 17 years':0, 'Left school at 18 years' : 0, \n",
    "               'Some college or university, no certificate or degree':1, 'Professional certificate/ diploma':2 ,'University degree':3, 'Masters degree':4, \n",
    "               'Doctorate degree' : 5}\n",
    "\n",
    "\n",
    "    for cols in lst:\n",
    "        drugs[cols]=drugs[cols].map(consDict)\n",
    "    \n",
    "    drugs['education'] = drugs['education'].map(eduDict)\n",
    "    return(drugs)\n",
    "\n",
    "def gender_dummy(drugs):\n",
    "    drugs['female'] = np.where(drugs['gender'] == 'female', 1, 0) \n",
    "    drugs = drugs.drop(columns=['gender', 'id'])\n",
    "    return (drugs)\n",
    "\n",
    "def expl_var_dummy(drugs):\n",
    "    drugs['consumption_cocaine_last_month'] = np.where(drugs['consumption_cocaine_last_month'] == 'Yes', 1, 0) \n",
    "    return (drugs)\n",
    "\n",
    "def scalling(drugs):\n",
    "    scaled_features = drugs.copy()\n",
    "\n",
    "    col_names = ['personality_neuroticism', 'personality_extraversion',\n",
    "                'personality_openness', 'personality_agreeableness',\n",
    "                'personality_conscientiousness', 'personality_impulsiveness',\n",
    "                'personality_sensation']\n",
    "    features = scaled_features[col_names]\n",
    "\n",
    "    scaler = RobustScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "\n",
    "    scaled_features[col_names] = features\n",
    "\n",
    "    return(scaled_features)\n",
    "    \n",
    "def our_metrics(y_test, preds):\n",
    "     print(f'Balanced Accuracy:', balanced_accuracy_score(y_test, preds), \n",
    "          '\\nconfusion:', confusion_matrix(y_test, preds),\n",
    "          '\\nprecision:', precision_score(y_test, preds) ,\n",
    "          '\\naccuracy:', accuracy_score(y_test, preds), \n",
    "          '\\nrecall:', recall_score(y_test, preds),\n",
    "          '\\nauroc:', roc_auc_score(y_test, preds) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['education', 'personality_neuroticism', 'personality_extraversion',\n",
      "       'personality_openness', 'personality_agreeableness',\n",
      "       'personality_conscientiousness', 'personality_impulsiveness',\n",
      "       'personality_sensation', 'consumption_alcohol',\n",
      "       'consumption_amphetamines', 'consumption_caffeine',\n",
      "       'consumption_cannabis', 'consumption_chocolate',\n",
      "       'consumption_mushrooms', 'consumption_nicotine',\n",
      "       'consumption_cocaine_last_month', '18-24', '25-34', '35-44', '45-54',\n",
      "       '55-64', '65+', 'Australia', 'New Zealand', 'UK', 'USA',\n",
      "       'Other_country', 'Asian', 'Black', 'Mixed-Black/Asian',\n",
      "       'Mixed-White/Asian', 'Mixed-White/Black', 'Other_y', 'White', 'female'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>personality_neuroticism</th>\n",
       "      <th>personality_extraversion</th>\n",
       "      <th>personality_openness</th>\n",
       "      <th>personality_agreeableness</th>\n",
       "      <th>personality_conscientiousness</th>\n",
       "      <th>personality_impulsiveness</th>\n",
       "      <th>personality_sensation</th>\n",
       "      <th>consumption_alcohol</th>\n",
       "      <th>consumption_amphetamines</th>\n",
       "      <th>consumption_caffeine</th>\n",
       "      <th>consumption_cannabis</th>\n",
       "      <th>consumption_chocolate</th>\n",
       "      <th>consumption_mushrooms</th>\n",
       "      <th>consumption_nicotine</th>\n",
       "      <th>consumption_cocaine_last_month</th>\n",
       "      <th>18-24</th>\n",
       "      <th>25-34</th>\n",
       "      <th>35-44</th>\n",
       "      <th>45-54</th>\n",
       "      <th>55-64</th>\n",
       "      <th>65+</th>\n",
       "      <th>Australia</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>UK</th>\n",
       "      <th>USA</th>\n",
       "      <th>Other_country</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Mixed-Black/Asian</th>\n",
       "      <th>Mixed-White/Asian</th>\n",
       "      <th>Mixed-White/Black</th>\n",
       "      <th>Other_y</th>\n",
       "      <th>White</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.287179</td>\n",
       "      <td>0.354680</td>\n",
       "      <td>-0.111588</td>\n",
       "      <td>-0.115607</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.978328</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.215385</td>\n",
       "      <td>0.832512</td>\n",
       "      <td>-0.300429</td>\n",
       "      <td>-0.115607</td>\n",
       "      <td>0.342697</td>\n",
       "      <td>-0.396476</td>\n",
       "      <td>-0.718266</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.287179</td>\n",
       "      <td>-0.334975</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>-0.242775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.889868</td>\n",
       "      <td>0.247678</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.015385</td>\n",
       "      <td>-0.931034</td>\n",
       "      <td>-0.390558</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>-1.016854</td>\n",
       "      <td>0.889868</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210256</td>\n",
       "      <td>0.600985</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>-0.421348</td>\n",
       "      <td>0.334802</td>\n",
       "      <td>0.247678</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   education  personality_neuroticism  personality_extraversion  \\\n",
       "0          4                 0.287179                  0.354680   \n",
       "1          3                -0.215385                  0.832512   \n",
       "2          3                 0.287179                 -0.334975   \n",
       "3          4                 1.015385                 -0.931034   \n",
       "4          1                 0.210256                  0.600985   \n",
       "\n",
       "   personality_openness  personality_agreeableness  \\\n",
       "0             -0.111588                  -0.115607   \n",
       "1             -0.300429                  -0.115607   \n",
       "2              0.111588                  -0.242775   \n",
       "3             -0.390558                   0.375723   \n",
       "4              0.751073                   0.942197   \n",
       "\n",
       "   personality_conscientiousness  personality_impulsiveness  \\\n",
       "0                       0.213483                   0.000000   \n",
       "1                       0.342697                  -0.396476   \n",
       "2                       0.000000                   0.889868   \n",
       "3                      -1.016854                   0.889868   \n",
       "4                      -0.421348                   0.334802   \n",
       "\n",
       "   personality_sensation  consumption_alcohol  consumption_amphetamines  \\\n",
       "0              -0.978328                    5                         1   \n",
       "1              -0.718266                    5                         0   \n",
       "2               0.247678                    4                         0   \n",
       "3               0.529412                    6                         0   \n",
       "4               0.247678                    5                         0   \n",
       "\n",
       "   consumption_caffeine  consumption_cannabis  consumption_chocolate  \\\n",
       "0                     6                     5                      6   \n",
       "1                     5                     0                      6   \n",
       "2                     6                     5                      5   \n",
       "3                     6                     2                      6   \n",
       "4                     4                     4                      6   \n",
       "\n",
       "   consumption_mushrooms  consumption_nicotine  \\\n",
       "0                      0                     5   \n",
       "1                      0                     0   \n",
       "2                      3                     4   \n",
       "3                      0                     2   \n",
       "4                      3                     4   \n",
       "\n",
       "   consumption_cocaine_last_month  18-24  25-34  35-44  45-54  55-64  65+  \\\n",
       "0                               0      0      0      0      1      0    0   \n",
       "1                               0      0      1      0      0      0    0   \n",
       "2                               0      1      0      0      0      0    0   \n",
       "3                               0      0      1      0      0      0    0   \n",
       "4                               0      1      0      0      0      0    0   \n",
       "\n",
       "   Australia  New Zealand  UK  USA  Other_country  Asian  Black  \\\n",
       "0          0            0   0    1              0      0      0   \n",
       "1          0            0   0    1              0      0      0   \n",
       "2          0            0   0    1              0      0      0   \n",
       "3          0            0   0    1              0      0      0   \n",
       "4          1            0   0    0              0      0      0   \n",
       "\n",
       "   Mixed-Black/Asian  Mixed-White/Asian  Mixed-White/Black  Other_y  White  \\\n",
       "0                  1                  0                  0        0      0   \n",
       "1                  1                  0                  0        0      0   \n",
       "2                  1                  0                  0        0      0   \n",
       "3                  1                  0                  0        0      0   \n",
       "4                  1                  0                  0        0      0   \n",
       "\n",
       "   female  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs = pd.read_csv('drugs_train.csv')\n",
    "\n",
    "drugs = getting_dummies(drugs)\n",
    "drugs = getting_ordinals(drugs)\n",
    "drugs = gender_dummy(drugs)\n",
    "drugs = expl_var_dummy(drugs)\n",
    "drugs = scalling(drugs)\n",
    "x_train, x_test, y_train, y_test = train_test_split(drugs.loc[:,drugs.columns!='consumption_cocaine_last_month'], drugs.consumption_cocaine_last_month, test_size=0.25)\n",
    "\n",
    "print(drugs.columns )\n",
    "drugs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    137\n",
       "1     13\n",
       "Name: consumption_cocaine_last_month, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.5528571428571429 \n",
      "confusion: [[345   5]\n",
      " [ 22   3]] \n",
      "precision: 0.375 \n",
      "accuracy: 0.928 \n",
      "recall: 0.12 \n",
      "auroc: 0.5528571428571429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reg = LogisticRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "reg_pred = reg.predict(x_test)\n",
    "\n",
    "our_metrics(y_test, reg_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.51 \n",
      "confusion: [[343   7]\n",
      " [ 24   1]] \n",
      "precision: 0.125 \n",
      "accuracy: 0.9173333333333333 \n",
      "recall: 0.04 \n",
      "auroc: 0.51\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lg = lgb.LGBMClassifier()\n",
    "lg.fit(x_train, y_train)\n",
    "lgb_preds = lg.predict(x_test)\n",
    "\n",
    "our_metrics(y_test, lgb_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 09:36:57,975]\u001b[0m A new study created in memory with name: no-name-3f14d5c3-e50d-4a31-91a7-ac2619a8b579\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:38:34,548]\u001b[0m Trial 0 finished with value: 0.5666087553417968 and parameters: {'n_estimators': 2941, 'learning_rate': 0.1547358871633316, 'lambda_l1': 5.304610961295152e-06, 'lambda_l2': 1.1194096153140269e-07, 'num_leaves': 10680, 'feature_fraction': 0.8217196196456307, 'bagging_fraction': 0.4313792263467209, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 0 with value: 0.5666087553417968.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:39:50,298]\u001b[0m Trial 1 finished with value: 0.5808095865933541 and parameters: {'n_estimators': 2369, 'learning_rate': 0.13039588734289487, 'lambda_l1': 2.0067864345751194e-08, 'lambda_l2': 1.0237127431897417, 'num_leaves': 8558, 'feature_fraction': 0.40875941861490606, 'bagging_fraction': 0.591520379532485, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 1 with value: 0.5808095865933541.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:40:46,290]\u001b[0m Trial 2 finished with value: 0.5758474065740636 and parameters: {'n_estimators': 3012, 'learning_rate': 0.266819642233958, 'lambda_l1': 2.475532067389947e-05, 'lambda_l2': 0.0035868044868220023, 'num_leaves': 6224, 'feature_fraction': 0.9014147403949067, 'bagging_fraction': 0.5647381013664604, 'bagging_freq': 4, 'min_child_samples': 62}. Best is trial 1 with value: 0.5808095865933541.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:43:37,371]\u001b[0m Trial 3 finished with value: 0.5722056251396935 and parameters: {'n_estimators': 5590, 'learning_rate': 0.2967310687019558, 'lambda_l1': 0.0035417360464418688, 'lambda_l2': 2.7939213528966846e-07, 'num_leaves': 11638, 'feature_fraction': 0.6241260452275169, 'bagging_fraction': 0.8445985036930219, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 1 with value: 0.5808095865933541.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:44:42,093]\u001b[0m Trial 4 finished with value: 0.6138834175550222 and parameters: {'n_estimators': 3053, 'learning_rate': 0.0826705100343561, 'lambda_l1': 0.0832473933851324, 'lambda_l2': 0.00015887965737217987, 'num_leaves': 7108, 'feature_fraction': 0.9109052705755406, 'bagging_fraction': 0.6389498337175296, 'bagging_freq': 7, 'min_child_samples': 131}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:45:57,253]\u001b[0m Trial 5 finished with value: 0.5701286979993289 and parameters: {'n_estimators': 2681, 'learning_rate': 0.14844332606565475, 'lambda_l1': 0.04970544432543437, 'lambda_l2': 0.073055556282392, 'num_leaves': 9227, 'feature_fraction': 0.44621654169426955, 'bagging_fraction': 0.8093905997862283, 'bagging_freq': 5, 'min_child_samples': 62}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:46:35,271]\u001b[0m Trial 6 finished with value: 0.5567237707937328 and parameters: {'n_estimators': 6411, 'learning_rate': 0.28134308181386275, 'lambda_l1': 0.00135726688122724, 'lambda_l2': 1.8574222104966077e-05, 'num_leaves': 5522, 'feature_fraction': 0.5259115458888612, 'bagging_fraction': 0.6241597442701426, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:47:02,967]\u001b[0m Trial 7 finished with value: 0.5881700621864134 and parameters: {'n_estimators': 1619, 'learning_rate': 0.011823703761812562, 'lambda_l1': 0.15607455042351545, 'lambda_l2': 0.0019307142679302685, 'num_leaves': 6008, 'feature_fraction': 0.87805695091017, 'bagging_fraction': 0.6555278423466775, 'bagging_freq': 1, 'min_child_samples': 117}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:49:03,002]\u001b[0m Trial 8 finished with value: 0.5946140637165819 and parameters: {'n_estimators': 4792, 'learning_rate': 0.28285220665529726, 'lambda_l1': 0.00938523447029628, 'lambda_l2': 8.156729164462641e-06, 'num_leaves': 9729, 'feature_fraction': 0.4624983440697865, 'bagging_fraction': 0.6348530368032013, 'bagging_freq': 3, 'min_child_samples': 121}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:53:43,179]\u001b[0m Trial 9 finished with value: 0.5990139308968306 and parameters: {'n_estimators': 6647, 'learning_rate': 0.2744835235025855, 'lambda_l1': 3.3900284844572426e-07, 'lambda_l2': 1.3204051610509644e-05, 'num_leaves': 10156, 'feature_fraction': 0.4542004770636912, 'bagging_fraction': 0.799083628298367, 'bagging_freq': 3, 'min_child_samples': 103}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:53:54,226]\u001b[0m Trial 10 finished with value: 0.5762304444271101 and parameters: {'n_estimators': 4036, 'learning_rate': 0.05984637779815362, 'lambda_l1': 1.335030935765781, 'lambda_l2': 0.0009093237742725358, 'num_leaves': 4148, 'feature_fraction': 0.9875777743231821, 'bagging_fraction': 0.9779213627371157, 'bagging_freq': 7, 'min_child_samples': 138}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 09:57:34,584]\u001b[0m Trial 11 finished with value: 0.5874113901863947 and parameters: {'n_estimators': 7652, 'learning_rate': 0.21283660249128913, 'lambda_l1': 4.4908235169112536e-07, 'lambda_l2': 5.400582183703088e-06, 'num_leaves': 7631, 'feature_fraction': 0.7126364699806862, 'bagging_fraction': 0.8124811555446506, 'bagging_freq': 7, 'min_child_samples': 98}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:01:19,028]\u001b[0m Trial 12 finished with value: 0.5930836411078071 and parameters: {'n_estimators': 7853, 'learning_rate': 0.08968835151925297, 'lambda_l1': 0.0001656501265040179, 'lambda_l2': 0.00015121624414014215, 'num_leaves': 7527, 'feature_fraction': 0.7056550080617131, 'bagging_fraction': 0.7465241422443089, 'bagging_freq': 2, 'min_child_samples': 100}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:05:20,700]\u001b[0m Trial 13 finished with value: 0.5868065220288091 and parameters: {'n_estimators': 4253, 'learning_rate': 0.21520327315747032, 'lambda_l1': 1.9148769335057128e-08, 'lambda_l2': 9.304289142045819e-07, 'num_leaves': 11879, 'feature_fraction': 0.5778426258350766, 'bagging_fraction': 0.9544089287658435, 'bagging_freq': 5, 'min_child_samples': 140}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:10:04,003]\u001b[0m Trial 14 finished with value: 0.606674258478092 and parameters: {'n_estimators': 6200, 'learning_rate': 0.09584037424726366, 'lambda_l1': 6.083993797599489e-07, 'lambda_l2': 6.922781664170923e-05, 'num_leaves': 9984, 'feature_fraction': 0.8191195722771215, 'bagging_fraction': 0.5266378396717406, 'bagging_freq': 3, 'min_child_samples': 92}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:10:44,782]\u001b[0m Trial 15 finished with value: 0.5528989191004119 and parameters: {'n_estimators': 1054, 'learning_rate': 0.09228235023895769, 'lambda_l1': 0.00040657719166608316, 'lambda_l2': 0.0002529054635492027, 'num_leaves': 8208, 'feature_fraction': 0.8016179158470146, 'bagging_fraction': 0.4884566887726526, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:12:53,478]\u001b[0m Trial 16 finished with value: 0.5946117164112801 and parameters: {'n_estimators': 5160, 'learning_rate': 0.036246614542856305, 'lambda_l1': 2.920220825104418e-06, 'lambda_l2': 0.017315958753734866, 'num_leaves': 6975, 'feature_fraction': 0.9608835183307968, 'bagging_fraction': 0.5323290875610793, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 4 with value: 0.6138834175550222.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:14:52,320]\u001b[0m Trial 17 finished with value: 0.6219063232661883 and parameters: {'n_estimators': 3539, 'learning_rate': 0.10125904342767522, 'lambda_l1': 3.2149278341267135e-05, 'lambda_l2': 1.5221263070748247e-08, 'num_leaves': 8801, 'feature_fraction': 0.7695785948753242, 'bagging_fraction': 0.448055740883199, 'bagging_freq': 1, 'min_child_samples': 120}. Best is trial 17 with value: 0.6219063232661883.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:17:17,166]\u001b[0m Trial 18 finished with value: 0.6157342884823286 and parameters: {'n_estimators': 3612, 'learning_rate': 0.11863825057333441, 'lambda_l1': 4.910734992726355e-05, 'lambda_l2': 1.6000742607901477e-08, 'num_leaves': 8921, 'feature_fraction': 0.7476198594920551, 'bagging_fraction': 0.406694652512141, 'bagging_freq': 1, 'min_child_samples': 121}. Best is trial 17 with value: 0.6219063232661883.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:19:54,597]\u001b[0m Trial 19 finished with value: 0.6162398136010936 and parameters: {'n_estimators': 3787, 'learning_rate': 0.19286514499365248, 'lambda_l1': 2.9763228973944354e-05, 'lambda_l2': 1.1323884180445289e-08, 'num_leaves': 8909, 'feature_fraction': 0.7600474101393854, 'bagging_fraction': 0.4115530973574254, 'bagging_freq': 1, 'min_child_samples': 116}. Best is trial 17 with value: 0.6219063232661883.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:21:41,489]\u001b[0m Trial 20 finished with value: 0.623270123918091 and parameters: {'n_estimators': 2000, 'learning_rate': 0.19049729189969378, 'lambda_l1': 1.0134335316591135e-05, 'lambda_l2': 1.567658312732769e-08, 'num_leaves': 11232, 'feature_fraction': 0.6323760344365301, 'bagging_fraction': 0.4729585553578256, 'bagging_freq': 1, 'min_child_samples': 110}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:23:40,545]\u001b[0m Trial 21 finished with value: 0.6181337868222576 and parameters: {'n_estimators': 1958, 'learning_rate': 0.19261923465472808, 'lambda_l1': 6.860807254916082e-06, 'lambda_l2': 1.1543708984383719e-08, 'num_leaves': 10906, 'feature_fraction': 0.631210012983598, 'bagging_fraction': 0.4628028397049688, 'bagging_freq': 1, 'min_child_samples': 109}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:25:27,370]\u001b[0m Trial 22 finished with value: 0.587373575108286 and parameters: {'n_estimators': 1814, 'learning_rate': 0.19272597719041112, 'lambda_l1': 3.5209654311184448e-06, 'lambda_l2': 6.475075533581892e-08, 'num_leaves': 11036, 'feature_fraction': 0.6321634654540144, 'bagging_fraction': 0.45756675077495657, 'bagging_freq': 2, 'min_child_samples': 85}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:27:26,063]\u001b[0m Trial 23 finished with value: 0.6132112468006914 and parameters: {'n_estimators': 2049, 'learning_rate': 0.24023211935705935, 'lambda_l1': 1.0810781598311852e-05, 'lambda_l2': 7.168955795088256e-07, 'num_leaves': 11091, 'feature_fraction': 0.6505381053685098, 'bagging_fraction': 0.488397133405317, 'bagging_freq': 1, 'min_child_samples': 105}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:28:30,291]\u001b[0m Trial 24 finished with value: 0.5941853237611882 and parameters: {'n_estimators': 1267, 'learning_rate': 0.18152852022208552, 'lambda_l1': 0.00019693651494377676, 'lambda_l2': 3.122950897202423e-08, 'num_leaves': 10570, 'feature_fraction': 0.5632417243654394, 'bagging_fraction': 0.4787618661505096, 'bagging_freq': 2, 'min_child_samples': 112}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:30:21,199]\u001b[0m Trial 25 finished with value: 0.5984850603457069 and parameters: {'n_estimators': 2280, 'learning_rate': 0.2398551005144761, 'lambda_l1': 2.1974691027844316e-07, 'lambda_l2': 1.6811772518129896e-07, 'num_leaves': 9464, 'feature_fraction': 0.6492437977377848, 'bagging_fraction': 0.5502263263220645, 'bagging_freq': 1, 'min_child_samples': 131}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:33:34,173]\u001b[0m Trial 26 finished with value: 0.5812385453946826 and parameters: {'n_estimators': 3201, 'learning_rate': 0.1646717764373182, 'lambda_l1': 1.488453932186423e-06, 'lambda_l2': 1.0433958595904846e-06, 'num_leaves': 11369, 'feature_fraction': 0.5337063406716467, 'bagging_fraction': 0.7225642674603728, 'bagging_freq': 2, 'min_child_samples': 82}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:35:04,839]\u001b[0m Trial 27 finished with value: 0.6082258022183613 and parameters: {'n_estimators': 1638, 'learning_rate': 0.12675687680337833, 'lambda_l1': 0.000722851717542416, 'lambda_l2': 1.1260140388649082e-08, 'num_leaves': 10242, 'feature_fraction': 0.6732173846167537, 'bagging_fraction': 0.5162293540404477, 'bagging_freq': 1, 'min_child_samples': 130}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:38:27,783]\u001b[0m Trial 28 finished with value: 0.6050859426517767 and parameters: {'n_estimators': 3461, 'learning_rate': 0.22790485163510493, 'lambda_l1': 1.2395867938226648e-07, 'lambda_l2': 4.6114009762076236e-08, 'num_leaves': 10858, 'feature_fraction': 0.5900970889503943, 'bagging_fraction': 0.44349144494091414, 'bagging_freq': 2, 'min_child_samples': 112}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:41:24,632]\u001b[0m Trial 29 finished with value: 0.5780181356399462 and parameters: {'n_estimators': 2581, 'learning_rate': 0.15826742307729957, 'lambda_l1': 6.3611354841727044e-06, 'lambda_l2': 1.4313516962146685e-07, 'num_leaves': 11986, 'feature_fraction': 0.7496882253750512, 'bagging_fraction': 0.5833781741105681, 'bagging_freq': 1, 'min_child_samples': 47}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:46:07,067]\u001b[0m Trial 30 finished with value: 0.5971563076877626 and parameters: {'n_estimators': 4728, 'learning_rate': 0.17002339689487925, 'lambda_l1': 5.983688195871736e-05, 'lambda_l2': 3.3874078179427196e-07, 'num_leaves': 10580, 'feature_fraction': 0.8517727565213149, 'bagging_fraction': 0.44168314242244844, 'bagging_freq': 2, 'min_child_samples': 92}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:49:12,358]\u001b[0m Trial 31 finished with value: 0.5990733082605486 and parameters: {'n_estimators': 3816, 'learning_rate': 0.18690477563005561, 'lambda_l1': 1.1330617550692314e-05, 'lambda_l2': 1.0444027006285434e-08, 'num_leaves': 8945, 'feature_fraction': 0.7628595314889999, 'bagging_fraction': 0.40245082755465844, 'bagging_freq': 1, 'min_child_samples': 112}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:51:17,280]\u001b[0m Trial 32 finished with value: 0.6133754566540681 and parameters: {'n_estimators': 2602, 'learning_rate': 0.2006824583436815, 'lambda_l1': 3.612174533189586e-05, 'lambda_l2': 2.913377464930628e-08, 'num_leaves': 8621, 'feature_fraction': 0.6966938664221379, 'bagging_fraction': 0.4094018022216683, 'bagging_freq': 1, 'min_child_samples': 122}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:54:21,974]\u001b[0m Trial 33 finished with value: 0.6095914091902783 and parameters: {'n_estimators': 3469, 'learning_rate': 0.14104397548954717, 'lambda_l1': 1.7780144194772922e-05, 'lambda_l2': 2.770025849576715e-06, 'num_leaves': 9676, 'feature_fraction': 0.7851371093777534, 'bagging_fraction': 0.4692369263071457, 'bagging_freq': 2, 'min_child_samples': 108}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:56:45,435]\u001b[0m Trial 34 finished with value: 0.6092896280159572 and parameters: {'n_estimators': 4292, 'learning_rate': 0.258448856614032, 'lambda_l1': 5.7399198485748646e-08, 'lambda_l2': 8.455711123603818e-08, 'num_leaves': 8022, 'feature_fraction': 0.603810747737188, 'bagging_fraction': 0.5089865812170348, 'bagging_freq': 1, 'min_child_samples': 127}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 10:58:17,764]\u001b[0m Trial 35 finished with value: 0.5953449486112845 and parameters: {'n_estimators': 2228, 'learning_rate': 0.10909300398082147, 'lambda_l1': 2.1600412180819795e-06, 'lambda_l2': 1.0000748331218773e-08, 'num_leaves': 8371, 'feature_fraction': 0.7367219463557606, 'bagging_fraction': 0.5933333292441729, 'bagging_freq': 2, 'min_child_samples': 95}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:00:43,036]\u001b[0m Trial 36 finished with value: 0.5942149081742211 and parameters: {'n_estimators': 2826, 'learning_rate': 0.20235910577725097, 'lambda_l1': 9.110077680603146e-05, 'lambda_l2': 3.26065788464592e-07, 'num_leaves': 11462, 'feature_fraction': 0.8415661244562905, 'bagging_fraction': 0.4360394063314284, 'bagging_freq': 3, 'min_child_samples': 77}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:02:55,856]\u001b[0m Trial 37 finished with value: 0.6191616804603669 and parameters: {'n_estimators': 3228, 'learning_rate': 0.16889842341386163, 'lambda_l1': 1.355251492592362e-06, 'lambda_l2': 0.9235633297031601, 'num_leaves': 9049, 'feature_fraction': 0.669156785922804, 'bagging_fraction': 0.557512472642964, 'bagging_freq': 1, 'min_child_samples': 117}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:05:31,410]\u001b[0m Trial 38 finished with value: 0.5900002791556198 and parameters: {'n_estimators': 3191, 'learning_rate': 0.14481704052894914, 'lambda_l1': 1.1739006302391221e-06, 'lambda_l2': 0.32933294856428363, 'num_leaves': 10319, 'feature_fraction': 0.5121618394866452, 'bagging_fraction': 0.5576678033577456, 'bagging_freq': 1, 'min_child_samples': 67}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:07:08,347]\u001b[0m Trial 39 finished with value: 0.600138306241582 and parameters: {'n_estimators': 1934, 'learning_rate': 0.1724880096437645, 'lambda_l1': 0.0027351918521591307, 'lambda_l2': 0.015757863838462085, 'num_leaves': 9272, 'feature_fraction': 0.6784580160146002, 'bagging_fraction': 0.6681434191722975, 'bagging_freq': 4, 'min_child_samples': 125}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:08:29,154]\u001b[0m Trial 40 finished with value: 0.5870134523939732 and parameters: {'n_estimators': 2933, 'learning_rate': 0.13617686236461773, 'lambda_l1': 8.880511751472675e-08, 'lambda_l2': 0.38269034698256643, 'num_leaves': 6944, 'feature_fraction': 0.611309506347015, 'bagging_fraction': 0.6019781683621663, 'bagging_freq': 5, 'min_child_samples': 49}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:10:49,523]\u001b[0m Trial 41 finished with value: 0.5955368701481348 and parameters: {'n_estimators': 3860, 'learning_rate': 0.1795198204224125, 'lambda_l1': 1.9329733700219274e-05, 'lambda_l2': 3.2085738529188125e-08, 'num_leaves': 8937, 'feature_fraction': 0.7815777068668219, 'bagging_fraction': 0.4949778689352463, 'bagging_freq': 1, 'min_child_samples': 116}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:11:48,063]\u001b[0m Trial 42 finished with value: 0.602373143235426 and parameters: {'n_estimators': 1387, 'learning_rate': 0.07109916434928103, 'lambda_l1': 6.201695852451276e-06, 'lambda_l2': 1.0399109739228349e-07, 'num_leaves': 9695, 'feature_fraction': 0.721879015301862, 'bagging_fraction': 0.45541119488775267, 'bagging_freq': 1, 'min_child_samples': 108}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:13:30,504]\u001b[0m Trial 43 finished with value: 0.5654571718150582 and parameters: {'n_estimators': 2421, 'learning_rate': 0.15796503139908974, 'lambda_l1': 1.2041885103252114e-06, 'lambda_l2': 4.1168829108554466e-05, 'num_leaves': 8649, 'feature_fraction': 0.6704320527838139, 'bagging_fraction': 0.41284546286236323, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:16:21,682]\u001b[0m Trial 44 finished with value: 0.6198507878409549 and parameters: {'n_estimators': 5274, 'learning_rate': 0.21527973252084454, 'lambda_l1': 0.00029370532630068537, 'lambda_l2': 2.4501068971033936e-08, 'num_leaves': 7779, 'feature_fraction': 0.5515605808284468, 'bagging_fraction': 0.43525785453914667, 'bagging_freq': 1, 'min_child_samples': 117}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:18:04,830]\u001b[0m Trial 45 finished with value: 0.6194476573099769 and parameters: {'n_estimators': 4474, 'learning_rate': 0.2271774882682491, 'lambda_l1': 0.00034719603537996656, 'lambda_l2': 1.2423166546597493, 'num_leaves': 6592, 'feature_fraction': 0.5378817431845809, 'bagging_fraction': 0.5401594496935458, 'bagging_freq': 2, 'min_child_samples': 132}. Best is trial 20 with value: 0.623270123918091.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:19:23,300]\u001b[0m Trial 46 finished with value: 0.6262971758216704 and parameters: {'n_estimators': 5327, 'learning_rate': 0.2551598306775818, 'lambda_l1': 0.0003606642254908768, 'lambda_l2': 1.1797273951472917, 'num_leaves': 5362, 'feature_fraction': 0.4973885094230821, 'bagging_fraction': 0.5455902254622914, 'bagging_freq': 2, 'min_child_samples': 133}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:20:28,371]\u001b[0m Trial 47 finished with value: 0.607629188156033 and parameters: {'n_estimators': 5588, 'learning_rate': 0.251326127831031, 'lambda_l1': 0.013252537777602868, 'lambda_l2': 1.4052606577934137, 'num_leaves': 4986, 'feature_fraction': 0.4109655002336181, 'bagging_fraction': 0.5325503827571489, 'bagging_freq': 3, 'min_child_samples': 135}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:22:02,118]\u001b[0m Trial 48 finished with value: 0.6077435674430237 and parameters: {'n_estimators': 5256, 'learning_rate': 0.29825838914089775, 'lambda_l1': 0.0003659412985610411, 'lambda_l2': 0.10754169258007111, 'num_leaves': 6592, 'feature_fraction': 0.5014300073170249, 'bagging_fraction': 0.6115902753177139, 'bagging_freq': 2, 'min_child_samples': 135}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:23:33,574]\u001b[0m Trial 49 finished with value: 0.6029984362093287 and parameters: {'n_estimators': 6230, 'learning_rate': 0.219854127112673, 'lambda_l1': 0.002553234931859017, 'lambda_l2': 0.06284070044854016, 'num_leaves': 5587, 'feature_fraction': 0.47649819193052523, 'bagging_fraction': 0.6728383860226206, 'bagging_freq': 4, 'min_child_samples': 140}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:24:28,627]\u001b[0m Trial 50 finished with value: 0.6027654104599203 and parameters: {'n_estimators': 5763, 'learning_rate': 0.2714765597649438, 'lambda_l1': 0.0011385517754812769, 'lambda_l2': 0.0003719065236443408, 'num_leaves': 4679, 'feature_fraction': 0.4238373399199154, 'bagging_fraction': 0.5790057136291034, 'bagging_freq': 3, 'min_child_samples': 128}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:25:47,279]\u001b[0m Trial 51 finished with value: 0.6119186023340404 and parameters: {'n_estimators': 4972, 'learning_rate': 0.22994638853103022, 'lambda_l1': 0.00018523530380363287, 'lambda_l2': 0.370842353329435, 'num_leaves': 6164, 'feature_fraction': 0.5432829451107967, 'bagging_fraction': 0.5575337072377754, 'bagging_freq': 1, 'min_child_samples': 121}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:27:17,332]\u001b[0m Trial 52 finished with value: 0.6040650248526175 and parameters: {'n_estimators': 4408, 'learning_rate': 0.20827979783702066, 'lambda_l1': 0.0003864618281757463, 'lambda_l2': 0.7212318452829078, 'num_leaves': 7588, 'feature_fraction': 0.5673725256589953, 'bagging_fraction': 0.49594502220675546, 'bagging_freq': 2, 'min_child_samples': 132}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:28:29,711]\u001b[0m Trial 53 finished with value: 0.5872825529597693 and parameters: {'n_estimators': 6900, 'learning_rate': 0.24854975767361603, 'lambda_l1': 0.0075532882564093426, 'lambda_l2': 0.17427099674837113, 'num_leaves': 6546, 'feature_fraction': 0.496436626636148, 'bagging_fraction': 0.9124701433764063, 'bagging_freq': 2, 'min_child_samples': 102}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:30:09,526]\u001b[0m Trial 54 finished with value: 0.6095750482939292 and parameters: {'n_estimators': 4623, 'learning_rate': 0.22712689458122204, 'lambda_l1': 8.184312925070008e-05, 'lambda_l2': 0.01017895052811709, 'num_leaves': 7218, 'feature_fraction': 0.558906407743425, 'bagging_fraction': 0.5370084869260943, 'bagging_freq': 1, 'min_child_samples': 119}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:31:36,672]\u001b[0m Trial 55 finished with value: 0.6040680019486535 and parameters: {'n_estimators': 5675, 'learning_rate': 0.2818600036756673, 'lambda_l1': 0.00017316808951688085, 'lambda_l2': 0.6550114797409173, 'num_leaves': 5683, 'feature_fraction': 0.47520574323114173, 'bagging_fraction': 0.6283111389199402, 'bagging_freq': 1, 'min_child_samples': 123}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:33:39,493]\u001b[0m Trial 56 finished with value: 0.623013801526722 and parameters: {'n_estimators': 5277, 'learning_rate': 0.26384471322222347, 'lambda_l1': 0.0007820537681697114, 'lambda_l2': 0.03909136587207835, 'num_leaves': 7868, 'feature_fraction': 0.44568320717409554, 'bagging_fraction': 0.5100208579232397, 'bagging_freq': 2, 'min_child_samples': 135}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:35:58,923]\u001b[0m Trial 57 finished with value: 0.6235569386601788 and parameters: {'n_estimators': 5243, 'learning_rate': 0.2624947806560727, 'lambda_l1': 0.031360664203778164, 'lambda_l2': 0.04656830990779351, 'num_leaves': 7908, 'feature_fraction': 0.4453410841494797, 'bagging_fraction': 0.4305666613343958, 'bagging_freq': 3, 'min_child_samples': 135}. Best is trial 46 with value: 0.6262971758216704.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:38:35,518]\u001b[0m Trial 58 finished with value: 0.6380924731368175 and parameters: {'n_estimators': 5380, 'learning_rate': 0.2582052724380316, 'lambda_l1': 0.3276759360501292, 'lambda_l2': 0.002666642689139735, 'num_leaves': 7797, 'feature_fraction': 0.43586655031630733, 'bagging_fraction': 0.4308564658802418, 'bagging_freq': 3, 'min_child_samples': 138}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:41:09,542]\u001b[0m Trial 59 finished with value: 0.6137217813613417 and parameters: {'n_estimators': 5841, 'learning_rate': 0.26317376116972896, 'lambda_l1': 0.3390436821771558, 'lambda_l2': 0.0039037203287659965, 'num_leaves': 7290, 'feature_fraction': 0.43853776911743536, 'bagging_fraction': 0.46845034094092486, 'bagging_freq': 3, 'min_child_samples': 137}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:43:37,204]\u001b[0m Trial 60 finished with value: 0.6168811042186132 and parameters: {'n_estimators': 5004, 'learning_rate': 0.03478380365244535, 'lambda_l1': 0.7537635114272601, 'lambda_l2': 0.04611206583618935, 'num_leaves': 7857, 'feature_fraction': 0.40570068468344017, 'bagging_fraction': 0.5034765158963952, 'bagging_freq': 4, 'min_child_samples': 127}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:46:31,183]\u001b[0m Trial 61 finished with value: 0.6159741229768485 and parameters: {'n_estimators': 5296, 'learning_rate': 0.28508165421438114, 'lambda_l1': 0.03580547240840882, 'lambda_l2': 0.0011649355104928765, 'num_leaves': 7909, 'feature_fraction': 0.4456363482949998, 'bagging_fraction': 0.42799586148183627, 'bagging_freq': 3, 'min_child_samples': 140}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:50:23,972]\u001b[0m Trial 62 finished with value: 0.6260967775825547 and parameters: {'n_estimators': 5972, 'learning_rate': 0.2438152056933699, 'lambda_l1': 0.10607167918449861, 'lambda_l2': 0.004769592124344151, 'num_leaves': 8273, 'feature_fraction': 0.48425891265888793, 'bagging_fraction': 0.44450604088174905, 'bagging_freq': 3, 'min_child_samples': 134}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:54:43,559]\u001b[0m Trial 63 finished with value: 0.6192621422401657 and parameters: {'n_estimators': 6698, 'learning_rate': 0.28977295848575313, 'lambda_l1': 0.11668927141760797, 'lambda_l2': 0.005546913363139947, 'num_leaves': 8210, 'feature_fraction': 0.4721397691528077, 'bagging_fraction': 0.47830561469631294, 'bagging_freq': 3, 'min_child_samples': 135}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:58:06,252]\u001b[0m Trial 64 finished with value: 0.6352578539165521 and parameters: {'n_estimators': 6011, 'learning_rate': 0.2399838045623951, 'lambda_l1': 0.040696808376873034, 'lambda_l2': 0.033948527715844126, 'num_leaves': 7427, 'feature_fraction': 0.4890352184444374, 'bagging_fraction': 0.425371517948159, 'bagging_freq': 3, 'min_child_samples': 131}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 11:58:59,620]\u001b[0m Trial 65 finished with value: 0.611606674719668 and parameters: {'n_estimators': 6009, 'learning_rate': 0.2422462378652022, 'lambda_l1': 0.06273111458183832, 'lambda_l2': 0.03139225759248043, 'num_leaves': 4242, 'feature_fraction': 0.4283460604274365, 'bagging_fraction': 0.4255745131948262, 'bagging_freq': 3, 'min_child_samples': 131}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:00:00,360]\u001b[0m Trial 66 finished with value: 0.6207328219133381 and parameters: {'n_estimators': 6969, 'learning_rate': 0.2723049278119976, 'lambda_l1': 0.2851523332236093, 'lambda_l2': 0.0017969706153701944, 'num_leaves': 5245, 'feature_fraction': 0.4925698633416166, 'bagging_fraction': 0.516108058488384, 'bagging_freq': 4, 'min_child_samples': 136}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:00:58,208]\u001b[0m Trial 67 finished with value: 0.5889517219857943 and parameters: {'n_estimators': 5538, 'learning_rate': 0.25436984334991114, 'lambda_l1': 0.020471792914518065, 'lambda_l2': 0.027448361303798935, 'num_leaves': 7451, 'feature_fraction': 0.46056901717083454, 'bagging_fraction': 0.4558772176142484, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:03:38,239]\u001b[0m Trial 68 finished with value: 0.6296070514572746 and parameters: {'n_estimators': 6342, 'learning_rate': 0.2643448314048142, 'lambda_l1': 0.23195145081915156, 'lambda_l2': 0.006110585262562952, 'num_leaves': 8303, 'feature_fraction': 0.5172108559924103, 'bagging_fraction': 0.42568126984766147, 'bagging_freq': 3, 'min_child_samples': 126}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:07:39,360]\u001b[0m Trial 69 finished with value: 0.6341362047649083 and parameters: {'n_estimators': 6504, 'learning_rate': 0.23694893571135173, 'lambda_l1': 1.3960718956984381, 'lambda_l2': 0.006897653529998716, 'num_leaves': 8477, 'feature_fraction': 0.5220888696197179, 'bagging_fraction': 0.4000806037624676, 'bagging_freq': 4, 'min_child_samples': 125}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:11:27,598]\u001b[0m Trial 70 finished with value: 0.6173898125816509 and parameters: {'n_estimators': 7458, 'learning_rate': 0.23643355055555237, 'lambda_l1': 0.9807326053763237, 'lambda_l2': 0.006526665588469776, 'num_leaves': 8233, 'feature_fraction': 0.5199781950091542, 'bagging_fraction': 0.41792099767728386, 'bagging_freq': 5, 'min_child_samples': 124}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:13:35,482]\u001b[0m Trial 71 finished with value: 0.6173887051019659 and parameters: {'n_estimators': 6459, 'learning_rate': 0.24816397118409805, 'lambda_l1': 0.3215525179067977, 'lambda_l2': 0.002230633378501589, 'num_leaves': 6972, 'feature_fraction': 0.4932927249674797, 'bagging_fraction': 0.4439833971284064, 'bagging_freq': 4, 'min_child_samples': 128}. Best is trial 58 with value: 0.6380924731368175.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:16:33,147]\u001b[0m Trial 72 finished with value: 0.6390715258261775 and parameters: {'n_estimators': 6024, 'learning_rate': 0.27315175432236966, 'lambda_l1': 0.12913992509206745, 'lambda_l2': 0.0005930429875434704, 'num_leaves': 8534, 'feature_fraction': 0.5230396883095172, 'bagging_fraction': 0.4068897683045902, 'bagging_freq': 3, 'min_child_samples': 140}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:19:50,461]\u001b[0m Trial 73 finished with value: 0.6213353647683126 and parameters: {'n_estimators': 6049, 'learning_rate': 0.274247448293034, 'lambda_l1': 0.13534598007317075, 'lambda_l2': 0.00042581031003110023, 'num_leaves': 8261, 'feature_fraction': 0.5261520219638707, 'bagging_fraction': 0.4023053642335839, 'bagging_freq': 3, 'min_child_samples': 139}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:23:26,560]\u001b[0m Trial 74 finished with value: 0.61266867671041 and parameters: {'n_estimators': 6305, 'learning_rate': 0.25904152003455244, 'lambda_l1': 0.5813197488465486, 'lambda_l2': 0.0006740612370540868, 'num_leaves': 8521, 'feature_fraction': 0.482207404805443, 'bagging_fraction': 0.40038439489772704, 'bagging_freq': 4, 'min_child_samples': 131}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:27:41,176]\u001b[0m Trial 75 finished with value: 0.6341923676496778 and parameters: {'n_estimators': 6602, 'learning_rate': 0.2879589739031078, 'lambda_l1': 0.22349366676961502, 'lambda_l2': 0.012374780458045947, 'num_leaves': 9244, 'feature_fraction': 0.5103195551648011, 'bagging_fraction': 0.4190017139076389, 'bagging_freq': 3, 'min_child_samples': 125}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:32:17,064]\u001b[0m Trial 76 finished with value: 0.622967653547829 and parameters: {'n_estimators': 7302, 'learning_rate': 0.2906484864852258, 'lambda_l1': 1.3101213887432037, 'lambda_l2': 0.013897869618760899, 'num_leaves': 9473, 'feature_fraction': 0.5823589774368182, 'bagging_fraction': 0.42302324336500163, 'bagging_freq': 3, 'min_child_samples': 125}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:36:27,102]\u001b[0m Trial 77 finished with value: 0.5964744479465853 and parameters: {'n_estimators': 6484, 'learning_rate': 0.27656636841941457, 'lambda_l1': 0.2208957708756767, 'lambda_l2': 0.0023383971603821623, 'num_leaves': 9200, 'feature_fraction': 0.5182838231670858, 'bagging_fraction': 0.7767647719027219, 'bagging_freq': 5, 'min_child_samples': 129}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:40:39,541]\u001b[0m Trial 78 finished with value: 0.6112579103946374 and parameters: {'n_estimators': 6049, 'learning_rate': 0.23719133235761086, 'lambda_l1': 0.49925872372624513, 'lambda_l2': 0.00756326839897432, 'num_leaves': 8730, 'feature_fraction': 0.5059402217302573, 'bagging_fraction': 0.4543501405403626, 'bagging_freq': 4, 'min_child_samples': 114}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:45:01,348]\u001b[0m Trial 79 finished with value: 0.5974195835228651 and parameters: {'n_estimators': 6663, 'learning_rate': 0.2991036279464907, 'lambda_l1': 0.08365278479732914, 'lambda_l2': 0.00010763939655321956, 'num_leaves': 8445, 'feature_fraction': 0.4649687327177528, 'bagging_fraction': 0.47844063062589787, 'bagging_freq': 3, 'min_child_samples': 125}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:50:27,413]\u001b[0m Trial 80 finished with value: 0.6082525128329495 and parameters: {'n_estimators': 6971, 'learning_rate': 0.2899731356457081, 'lambda_l1': 0.08504408652694939, 'lambda_l2': 0.0010789816510231543, 'num_leaves': 10023, 'feature_fraction': 0.5368270425000194, 'bagging_fraction': 0.44494872819717585, 'bagging_freq': 3, 'min_child_samples': 119}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:53:39,395]\u001b[0m Trial 81 finished with value: 0.6292212066897177 and parameters: {'n_estimators': 5460, 'learning_rate': 0.2667371675616937, 'lambda_l1': 0.03853110089155618, 'lambda_l2': 0.003870808382278951, 'num_leaves': 8003, 'feature_fraction': 0.45701568490248007, 'bagging_fraction': 0.4224535654638297, 'bagging_freq': 3, 'min_child_samples': 133}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:56:51,956]\u001b[0m Trial 82 finished with value: 0.6291410146875129 and parameters: {'n_estimators': 5880, 'learning_rate': 0.2449283562495093, 'lambda_l1': 0.1693730332161129, 'lambda_l2': 0.003923566407030641, 'num_leaves': 8031, 'feature_fraction': 0.4251368617322904, 'bagging_fraction': 0.4221275211819958, 'bagging_freq': 3, 'min_child_samples': 132}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 12:59:54,019]\u001b[0m Trial 83 finished with value: 0.6151373272363063 and parameters: {'n_estimators': 5495, 'learning_rate': 0.2678822537893871, 'lambda_l1': 0.17654438859887725, 'lambda_l2': 0.0029566643872784596, 'num_leaves': 8079, 'feature_fraction': 0.41866802230299094, 'bagging_fraction': 0.4167130864939875, 'bagging_freq': 3, 'min_child_samples': 129}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:02:57,667]\u001b[0m Trial 84 finished with value: 0.6279313913124692 and parameters: {'n_estimators': 5847, 'learning_rate': 0.25453441451176045, 'lambda_l1': 0.039321355556965164, 'lambda_l2': 0.024494310117227507, 'num_leaves': 7563, 'feature_fraction': 0.45927897967808673, 'bagging_fraction': 0.40120301132711583, 'bagging_freq': 4, 'min_child_samples': 122}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:06:35,404]\u001b[0m Trial 85 finished with value: 0.6150249901717127 and parameters: {'n_estimators': 5824, 'learning_rate': 0.2791497182007539, 'lambda_l1': 0.05394046216514312, 'lambda_l2': 0.02089039922485099, 'num_leaves': 7434, 'feature_fraction': 0.4266444955710566, 'bagging_fraction': 0.4207828030131943, 'bagging_freq': 4, 'min_child_samples': 140}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:10:19,144]\u001b[0m Trial 86 finished with value: 0.6174450945539203 and parameters: {'n_estimators': 6185, 'learning_rate': 0.26698086961428175, 'lambda_l1': 0.004995790468656073, 'lambda_l2': 0.009692814414865398, 'num_leaves': 7667, 'feature_fraction': 0.4670360946559294, 'bagging_fraction': 0.46382119836844593, 'bagging_freq': 4, 'min_child_samples': 121}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:14:38,213]\u001b[0m Trial 87 finished with value: 0.6044535651309572 and parameters: {'n_estimators': 6823, 'learning_rate': 0.2320559425042332, 'lambda_l1': 0.019578974615876866, 'lambda_l2': 0.00130850776330208, 'num_leaves': 8044, 'feature_fraction': 0.40076531593815073, 'bagging_fraction': 0.4028072561187326, 'bagging_freq': 6, 'min_child_samples': 126}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:16:56,840]\u001b[0m Trial 88 finished with value: 0.5864718033922653 and parameters: {'n_estimators': 6408, 'learning_rate': 0.24855624099791213, 'lambda_l1': 0.47037760155326064, 'lambda_l2': 0.10641145988792414, 'num_leaves': 6816, 'feature_fraction': 0.4520419497259717, 'bagging_fraction': 0.43141696323951617, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:20:02,231]\u001b[0m Trial 89 finished with value: 0.6233000390985948 and parameters: {'n_estimators': 5457, 'learning_rate': 0.2569840637912165, 'lambda_l1': 0.037217788754040554, 'lambda_l2': 0.000641275456284409, 'num_leaves': 8513, 'feature_fraction': 0.43112950850308185, 'bagging_fraction': 0.4160587594943876, 'bagging_freq': 4, 'min_child_samples': 138}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:22:07,933]\u001b[0m Trial 90 finished with value: 0.5858940153612181 and parameters: {'n_estimators': 7132, 'learning_rate': 0.22069843685836846, 'lambda_l1': 1.4525295197320653, 'lambda_l2': 0.012112510580149023, 'num_leaves': 7665, 'feature_fraction': 0.5117288116760174, 'bagging_fraction': 0.8436645068070626, 'bagging_freq': 4, 'min_child_samples': 123}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:25:16,499]\u001b[0m Trial 91 finished with value: 0.6233715514962487 and parameters: {'n_estimators': 5050, 'learning_rate': 0.25279820753604276, 'lambda_l1': 0.2093316294686549, 'lambda_l2': 0.0037241749781695642, 'num_leaves': 8722, 'feature_fraction': 0.45749452557603004, 'bagging_fraction': 0.4831740282513546, 'bagging_freq': 3, 'min_child_samples': 132}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:28:20,209]\u001b[0m Trial 92 finished with value: 0.6107883332309643 and parameters: {'n_estimators': 4854, 'learning_rate': 0.28592153300802603, 'lambda_l1': 0.14814344483924968, 'lambda_l2': 0.00021848520278596508, 'num_leaves': 9065, 'feature_fraction': 0.48752998568788697, 'bagging_fraction': 0.43599169737304655, 'bagging_freq': 3, 'min_child_samples': 114}. Best is trial 72 with value: 0.6390715258261775.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:32:36,948]\u001b[0m Trial 93 finished with value: 0.6397152485076318 and parameters: {'n_estimators': 6565, 'learning_rate': 0.25647714402516236, 'lambda_l1': 0.8081042370292969, 'lambda_l2': 0.02450701289162699, 'num_leaves': 9436, 'feature_fraction': 0.5506627040792135, 'bagging_fraction': 0.40123637266827133, 'bagging_freq': 3, 'min_child_samples': 133}. Best is trial 93 with value: 0.6397152485076318.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:36:43,967]\u001b[0m Trial 94 finished with value: 0.6163367517645477 and parameters: {'n_estimators': 6570, 'learning_rate': 0.2701162905043063, 'lambda_l1': 0.7744813039286835, 'lambda_l2': 0.025833299320885624, 'num_leaves': 9424, 'feature_fraction': 0.5527333922450693, 'bagging_fraction': 0.41526062505719713, 'bagging_freq': 3, 'min_child_samples': 129}. Best is trial 93 with value: 0.6397152485076318.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:39:40,229]\u001b[0m Trial 95 finished with value: 0.6326630029066351 and parameters: {'n_estimators': 6278, 'learning_rate': 0.24357104568209598, 'lambda_l1': 0.4107609766233516, 'lambda_l2': 0.018927355265339254, 'num_leaves': 7452, 'feature_fraction': 0.5281730679095662, 'bagging_fraction': 0.4590319662620441, 'bagging_freq': 3, 'min_child_samples': 137}. Best is trial 93 with value: 0.6397152485076318.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:42:28,087]\u001b[0m Trial 96 finished with value: 0.628094111387625 and parameters: {'n_estimators': 6307, 'learning_rate': 0.24464105863652907, 'lambda_l1': 0.41936387839672723, 'lambda_l2': 0.07715042717599303, 'num_leaves': 7275, 'feature_fraction': 0.5683696313726857, 'bagging_fraction': 0.4616518255555161, 'bagging_freq': 3, 'min_child_samples': 137}. Best is trial 93 with value: 0.6397152485076318.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:46:05,912]\u001b[0m Trial 97 finished with value: 0.6243744134641466 and parameters: {'n_estimators': 6163, 'learning_rate': 0.278300630697003, 'lambda_l1': 0.872669369305268, 'lambda_l2': 0.0077980187455917276, 'num_leaves': 8844, 'feature_fraction': 0.6079297944710472, 'bagging_fraction': 0.45018831104585494, 'bagging_freq': 3, 'min_child_samples': 133}. Best is trial 93 with value: 0.6397152485076318.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:49:10,839]\u001b[0m Trial 98 finished with value: 0.6400432903523962 and parameters: {'n_estimators': 6756, 'learning_rate': 0.23307573473652426, 'lambda_l1': 0.2088746549420361, 'lambda_l2': 0.0017888964399385525, 'num_leaves': 7083, 'feature_fraction': 0.5342126511516654, 'bagging_fraction': 0.43315871661958205, 'bagging_freq': 3, 'min_child_samples': 137}. Best is trial 98 with value: 0.6400432903523962.\u001b[0m\n",
      "\u001b[32m[I 2022-05-22 13:52:15,385]\u001b[0m Trial 99 finished with value: 0.6359408154702292 and parameters: {'n_estimators': 6765, 'learning_rate': 0.23708914398242267, 'lambda_l1': 0.2463223021149878, 'lambda_l2': 0.0017165502556511277, 'num_leaves': 6710, 'feature_fraction': 0.5910297924279978, 'bagging_fraction': 0.43645078387514, 'bagging_freq': 3, 'min_child_samples': 137}. Best is trial 98 with value: 0.6400432903523962.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.6400432903523962\n",
      "  Params: \n",
      "    n_estimators: 6756\n",
      "    learning_rate: 0.23307573473652426\n",
      "    lambda_l1: 0.2088746549420361\n",
      "    lambda_l2: 0.0017888964399385525\n",
      "    num_leaves: 7083\n",
      "    feature_fraction: 0.5342126511516654\n",
      "    bagging_fraction: 0.43315871661958205\n",
      "    bagging_freq: 3\n",
      "    min_child_samples: 137\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "def objective(trial):\n",
    "    \n",
    "    #train_x, valid_x, train_y, valid_y = train_test_split(drugs.loc[:,drugs.columns!='consumption_cocaine_last_month'], drugs.consumption_cocaine_last_month, test_size=0.1, random_state = 112)\n",
    "    #dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 8000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 1.5, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 1.5, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 4000, 12000),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 140),\n",
    "    }\n",
    "\n",
    "    lst = []\n",
    "    for i in range(10):\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(drugs.loc[:,drugs.columns!='consumption_cocaine_last_month'], drugs.consumption_cocaine_last_month, test_size=0.1, random_state = i+1)\n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "        gbm = lgb.train(param, dtrain)\n",
    "        preds = gbm.predict(valid_x)\n",
    "        #pred_labels = np.rint(preds)\n",
    "        pred_labels1 = np.where(preds>0.4,1,0)\n",
    "        # pred_labels2 = np.where(preds>0.4,1,0)\n",
    "        # pred_labels3 = np.where(preds>0.2,1,0)\n",
    "        # pred_labels4 = np.where(preds>0.1,1,0)\n",
    "        x1 = balanced_accuracy_score(valid_y, pred_labels1)\n",
    "        # x2 = balanced_accuracy_score(valid_y, pred_labels2)\n",
    "        # x3 = balanced_accuracy_score(valid_y, pred_labels3)\n",
    "        # x4 = balanced_accuracy_score(valid_y, pred_labels4)\n",
    "        pred_labels = x1 #max(x1, x2, x3, x4)\n",
    "        lst.append(pred_labels)\n",
    "        #lst.append(balanced_accuracy_score(valid_y, pred_labels))\n",
    "    accuracy = np.mean(lst) \n",
    "        #sklearn.metrics.balanced_accuracy_score(valid_y, pred_labels)\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    \n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 6584,\n",
       " 'learning_rate': 0.2585180342596222,\n",
       " 'lambda_l1': 0.24869615891449395,\n",
       " 'lambda_l2': 1.5185272830960025e-07,\n",
       " 'num_leaves': 5328,\n",
       " 'feature_fraction': 0.5516054799322556,\n",
       " 'bagging_fraction': 0.9202901878168293,\n",
       " 'bagging_freq': 7,\n",
       " 'min_child_samples': 127}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.5162505380972879 \n",
      "confusion: [[191  11]\n",
      " [ 21   2]] \n",
      "precision: 0.15384615384615385 \n",
      "accuracy: 0.8577777777777778 \n",
      "recall: 0.08695652173913043 \n",
      "auroc: 0.5162505380972879\n",
      "Balanced Accuracy: 0.5597287989668531 \n",
      "confusion: [[191  11]\n",
      " [ 19   4]] \n",
      "precision: 0.26666666666666666 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.17391304347826086 \n",
      "auroc: 0.5597287989668531\n",
      "Balanced Accuracy: 0.5210781808891161 \n",
      "confusion: [[193  13]\n",
      " [ 17   2]] \n",
      "precision: 0.13333333333333333 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.10526315789473684 \n",
      "auroc: 0.521078180889116\n",
      "Balanced Accuracy: 0.6159825870646767 \n",
      "confusion: [[189  12]\n",
      " [ 17   7]] \n",
      "precision: 0.3684210526315789 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.2916666666666667 \n",
      "auroc: 0.6159825870646767\n",
      "Balanced Accuracy: 0.5809913132345427 \n",
      "confusion: [[196  10]\n",
      " [ 15   4]] \n",
      "precision: 0.2857142857142857 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.21052631578947367 \n",
      "auroc: 0.5809913132345427\n",
      "Balanced Accuracy: 0.5486211901306242 \n",
      "confusion: [[200  12]\n",
      " [ 11   2]] \n",
      "precision: 0.14285714285714285 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.15384615384615385 \n",
      "auroc: 0.548621190130624\n",
      "Balanced Accuracy: 0.49872557349192864 \n",
      "confusion: [[194  20]\n",
      " [ 10   1]] \n",
      "precision: 0.047619047619047616 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.09090909090909091 \n",
      "auroc: 0.4987255734919286\n",
      "Balanced Accuracy: 0.5893719806763285 \n",
      "confusion: [[198   9]\n",
      " [ 14   4]] \n",
      "precision: 0.3076923076923077 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.2222222222222222 \n",
      "auroc: 0.5893719806763286\n",
      "Balanced Accuracy: 0.5536585365853659 \n",
      "confusion: [[186  19]\n",
      " [ 16   4]] \n",
      "precision: 0.17391304347826086 \n",
      "accuracy: 0.8444444444444444 \n",
      "recall: 0.2 \n",
      "auroc: 0.5536585365853659\n",
      "Balanced Accuracy: 0.49536483253588515 \n",
      "confusion: [[194  15]\n",
      " [ 15   1]] \n",
      "precision: 0.0625 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.0625 \n",
      "auroc: 0.49536483253588515\n",
      "Balanced Accuracy: 0.5395658263305322 \n",
      "confusion: [[191  13]\n",
      " [ 18   3]] \n",
      "precision: 0.1875 \n",
      "accuracy: 0.8622222222222222 \n",
      "recall: 0.14285714285714285 \n",
      "auroc: 0.5395658263305322\n",
      "Balanced Accuracy: 0.5927715500579822 \n",
      "confusion: [[190   9]\n",
      " [ 20   6]] \n",
      "precision: 0.4 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.23076923076923078 \n",
      "auroc: 0.5927715500579823\n",
      "Balanced Accuracy: 0.5817621464829587 \n",
      "confusion: [[187  10]\n",
      " [ 22   6]] \n",
      "precision: 0.375 \n",
      "accuracy: 0.8577777777777778 \n",
      "recall: 0.21428571428571427 \n",
      "auroc: 0.5817621464829585\n",
      "Balanced Accuracy: 0.5353506787330317 \n",
      "confusion: [[186  22]\n",
      " [ 14   3]] \n",
      "precision: 0.12 \n",
      "accuracy: 0.84 \n",
      "recall: 0.17647058823529413 \n",
      "auroc: 0.5353506787330317\n",
      "Balanced Accuracy: 0.5137966274910577 \n",
      "confusion: [[190  16]\n",
      " [ 17   2]] \n",
      "precision: 0.1111111111111111 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.10526315789473684 \n",
      "auroc: 0.5137966274910577\n",
      "Balanced Accuracy: 0.6751207729468599 \n",
      "confusion: [[199   8]\n",
      " [ 11   7]] \n",
      "precision: 0.4666666666666667 \n",
      "accuracy: 0.9155555555555556 \n",
      "recall: 0.3888888888888889 \n",
      "auroc: 0.6751207729468599\n",
      "Balanced Accuracy: 0.5362318840579711 \n",
      "confusion: [[199   8]\n",
      " [ 16   2]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.1111111111111111 \n",
      "auroc: 0.5362318840579711\n",
      "Balanced Accuracy: 0.6034688995215312 \n",
      "confusion: [[200   9]\n",
      " [ 12   4]] \n",
      "precision: 0.3076923076923077 \n",
      "accuracy: 0.9066666666666666 \n",
      "recall: 0.25 \n",
      "auroc: 0.6034688995215312\n",
      "Balanced Accuracy: 0.6195652173913044 \n",
      "confusion: [[199   8]\n",
      " [ 13   5]] \n",
      "precision: 0.38461538461538464 \n",
      "accuracy: 0.9066666666666666 \n",
      "recall: 0.2777777777777778 \n",
      "auroc: 0.6195652173913043\n",
      "Balanced Accuracy: 0.5593891402714932 \n",
      "confusion: [[196  12]\n",
      " [ 14   3]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.17647058823529413 \n",
      "auroc: 0.5593891402714932\n",
      "Balanced Accuracy: 0.6497584541062802 \n",
      "confusion: [[200   7]\n",
      " [ 12   6]] \n",
      "precision: 0.46153846153846156 \n",
      "accuracy: 0.9155555555555556 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.6497584541062802\n",
      "Balanced Accuracy: 0.6221450962830273 \n",
      "confusion: [[188  15]\n",
      " [ 15   7]] \n",
      "precision: 0.3181818181818182 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.3181818181818182 \n",
      "auroc: 0.6221450962830273\n",
      "Balanced Accuracy: 0.5078011611030478 \n",
      "confusion: [[199  13]\n",
      " [ 12   1]] \n",
      "precision: 0.07142857142857142 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.07692307692307693 \n",
      "auroc: 0.5078011611030478\n",
      "Balanced Accuracy: 0.5558623619371283 \n",
      "confusion: [[199  15]\n",
      " [  9   2]] \n",
      "precision: 0.11764705882352941 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.18181818181818182 \n",
      "auroc: 0.5558623619371283\n",
      "Balanced Accuracy: 0.6332013574660633 \n",
      "confusion: [[190  18]\n",
      " [ 11   6]] \n",
      "precision: 0.25 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.35294117647058826 \n",
      "auroc: 0.6332013574660633\n",
      "Balanced Accuracy: 0.5957317073170731 \n",
      "confusion: [[193  12]\n",
      " [ 15   5]] \n",
      "precision: 0.29411764705882354 \n",
      "accuracy: 0.88 \n",
      "recall: 0.25 \n",
      "auroc: 0.5957317073170731\n",
      "Balanced Accuracy: 0.5285714285714286 \n",
      "confusion: [[194  16]\n",
      " [ 13   2]] \n",
      "precision: 0.1111111111111111 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.13333333333333333 \n",
      "auroc: 0.5285714285714286\n",
      "Balanced Accuracy: 0.6275000000000001 \n",
      "confusion: [[187  13]\n",
      " [ 17   8]] \n",
      "precision: 0.38095238095238093 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.32 \n",
      "auroc: 0.6275000000000001\n",
      "Balanced Accuracy: 0.6674208144796381 \n",
      "confusion: [[192  16]\n",
      " [ 10   7]] \n",
      "precision: 0.30434782608695654 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.4117647058823529 \n",
      "auroc: 0.6674208144796381\n",
      "Balanced Accuracy: 0.5509796806966618 \n",
      "confusion: [[201  11]\n",
      " [ 11   2]] \n",
      "precision: 0.15384615384615385 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.15384615384615385 \n",
      "auroc: 0.5509796806966617\n",
      "Balanced Accuracy: 0.6359756097560976 \n",
      "confusion: [[189  16]\n",
      " [ 13   7]] \n",
      "precision: 0.30434782608695654 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.35 \n",
      "auroc: 0.6359756097560977\n",
      "Balanced Accuracy: 0.602452733776188 \n",
      "confusion: [[194  12]\n",
      " [ 14   5]] \n",
      "precision: 0.29411764705882354 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.2631578947368421 \n",
      "auroc: 0.602452733776188\n",
      "Balanced Accuracy: 0.54 \n",
      "confusion: [[192   8]\n",
      " [ 22   3]] \n",
      "precision: 0.2727272727272727 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.12 \n",
      "auroc: 0.54\n",
      "Balanced Accuracy: 0.5668584969532836 \n",
      "confusion: [[194  17]\n",
      " [ 11   3]] \n",
      "precision: 0.15 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.21428571428571427 \n",
      "auroc: 0.5668584969532836\n",
      "Balanced Accuracy: 0.5674342105263157 \n",
      "confusion: [[198  11]\n",
      " [ 13   3]] \n",
      "precision: 0.21428571428571427 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.1875 \n",
      "auroc: 0.5674342105263158\n",
      "Balanced Accuracy: 0.5251696832579186 \n",
      "confusion: [[194  14]\n",
      " [ 15   2]] \n",
      "precision: 0.125 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.11764705882352941 \n",
      "auroc: 0.5251696832579186\n",
      "Balanced Accuracy: 0.5658263305322129 \n",
      "confusion: [[192  12]\n",
      " [ 17   4]] \n",
      "precision: 0.25 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.19047619047619047 \n",
      "auroc: 0.5658263305322129\n",
      "Balanced Accuracy: 0.5772946859903382 \n",
      "confusion: [[193  14]\n",
      " [ 14   4]] \n",
      "precision: 0.2222222222222222 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.2222222222222222 \n",
      "auroc: 0.5772946859903383\n",
      "Balanced Accuracy: 0.6134950248756219 \n",
      "confusion: [[188  13]\n",
      " [ 17   7]] \n",
      "precision: 0.35 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.2916666666666667 \n",
      "auroc: 0.6134950248756219\n",
      "Balanced Accuracy: 0.5634146341463415 \n",
      "confusion: [[190  15]\n",
      " [ 16   4]] \n",
      "precision: 0.21052631578947367 \n",
      "accuracy: 0.8622222222222222 \n",
      "recall: 0.2 \n",
      "auroc: 0.5634146341463415\n",
      "Balanced Accuracy: 0.6384146341463415 \n",
      "confusion: [[190  15]\n",
      " [ 13   7]] \n",
      "precision: 0.3181818181818182 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.35 \n",
      "auroc: 0.6384146341463416\n",
      "Balanced Accuracy: 0.5539632781012092 \n",
      "confusion: [[188  15]\n",
      " [ 18   4]] \n",
      "precision: 0.21052631578947367 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.18181818181818182 \n",
      "auroc: 0.5539632781012092\n",
      "Balanced Accuracy: 0.6013169073916738 \n",
      "confusion: [[199  15]\n",
      " [  8   3]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.2727272727272727 \n",
      "auroc: 0.6013169073916738\n",
      "Balanced Accuracy: 0.5362318840579711 \n",
      "confusion: [[199   8]\n",
      " [ 16   2]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.1111111111111111 \n",
      "auroc: 0.5362318840579711\n",
      "Balanced Accuracy: 0.6109943977591037 \n",
      "confusion: [[191  13]\n",
      " [ 15   6]] \n",
      "precision: 0.3157894736842105 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.2857142857142857 \n",
      "auroc: 0.6109943977591036\n",
      "Balanced Accuracy: 0.6231857764876633 \n",
      "confusion: [[199  13]\n",
      " [  9   4]] \n",
      "precision: 0.23529411764705882 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.3076923076923077 \n",
      "auroc: 0.6231857764876633\n",
      "Balanced Accuracy: 0.6023809523809524 \n",
      "confusion: [[197  13]\n",
      " [ 11   4]] \n",
      "precision: 0.23529411764705882 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.26666666666666666 \n",
      "auroc: 0.6023809523809524\n",
      "Balanced Accuracy: 0.5840797133900582 \n",
      "confusion: [[191  12]\n",
      " [ 17   5]] \n",
      "precision: 0.29411764705882354 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.22727272727272727 \n",
      "auroc: 0.5840797133900582\n",
      "Balanced Accuracy: 0.5166666666666667 \n",
      "confusion: [[203   7]\n",
      " [ 14   1]] \n",
      "precision: 0.125 \n",
      "accuracy: 0.9066666666666666 \n",
      "recall: 0.06666666666666667 \n",
      "auroc: 0.5166666666666666\n",
      "Balanced Accuracy: 0.6596140825998646 \n",
      "confusion: [[203   8]\n",
      " [  9   5]] \n",
      "precision: 0.38461538461538464 \n",
      "accuracy: 0.9244444444444444 \n",
      "recall: 0.35714285714285715 \n",
      "auroc: 0.6596140825998646\n",
      "Balanced Accuracy: 0.5845410628019323 \n",
      "confusion: [[196  11]\n",
      " [ 14   4]] \n",
      "precision: 0.26666666666666666 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.2222222222222222 \n",
      "auroc: 0.5845410628019324\n",
      "Balanced Accuracy: 0.6500282805429864 \n",
      "confusion: [[197  11]\n",
      " [ 11   6]] \n",
      "precision: 0.35294117647058826 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.35294117647058826 \n",
      "auroc: 0.6500282805429864\n",
      "Balanced Accuracy: 0.5749299719887955 \n",
      "confusion: [[186  18]\n",
      " [ 16   5]] \n",
      "precision: 0.21739130434782608 \n",
      "accuracy: 0.8488888888888889 \n",
      "recall: 0.23809523809523808 \n",
      "auroc: 0.5749299719887955\n",
      "Balanced Accuracy: 0.6678743961352657 \n",
      "confusion: [[196  11]\n",
      " [ 11   7]] \n",
      "precision: 0.3888888888888889 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.3888888888888889 \n",
      "auroc: 0.6678743961352657\n",
      "Balanced Accuracy: 0.6097342871742463 \n",
      "confusion: [[197   9]\n",
      " [ 14   5]] \n",
      "precision: 0.35714285714285715 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.2631578947368421 \n",
      "auroc: 0.6097342871742463\n",
      "Balanced Accuracy: 0.6522133526850508 \n",
      "confusion: [[195  17]\n",
      " [  8   5]] \n",
      "precision: 0.22727272727272727 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.38461538461538464 \n",
      "auroc: 0.6522133526850508\n",
      "Balanced Accuracy: 0.6666666666666667 \n",
      "confusion: [[196  14]\n",
      " [  9   6]] \n",
      "precision: 0.3 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.4 \n",
      "auroc: 0.6666666666666666\n",
      "Balanced Accuracy: 0.5870827285921626 \n",
      "confusion: [[200  12]\n",
      " [ 10   3]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.23076923076923078 \n",
      "auroc: 0.5870827285921626\n",
      "Balanced Accuracy: 0.6824229691876751 \n",
      "confusion: [[191  13]\n",
      " [ 12   9]] \n",
      "precision: 0.4090909090909091 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.42857142857142855 \n",
      "auroc: 0.6824229691876751\n",
      "Balanced Accuracy: 0.5305639259578132 \n",
      "confusion: [[188  14]\n",
      " [ 20   3]] \n",
      "precision: 0.17647058823529413 \n",
      "accuracy: 0.8488888888888889 \n",
      "recall: 0.13043478260869565 \n",
      "auroc: 0.5305639259578131\n",
      "Balanced Accuracy: 0.673170731707317 \n",
      "confusion: [[194  11]\n",
      " [ 12   8]] \n",
      "precision: 0.42105263157894735 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.4 \n",
      "auroc: 0.673170731707317\n",
      "Balanced Accuracy: 0.6524321266968326 \n",
      "confusion: [[198  10]\n",
      " [ 11   6]] \n",
      "precision: 0.375 \n",
      "accuracy: 0.9066666666666666 \n",
      "recall: 0.35294117647058826 \n",
      "auroc: 0.6524321266968326\n",
      "Balanced Accuracy: 0.533214103219213 \n",
      "confusion: [[198   8]\n",
      " [ 17   2]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.10526315789473684 \n",
      "auroc: 0.533214103219213\n",
      "Balanced Accuracy: 0.5775 \n",
      "confusion: [[191   9]\n",
      " [ 20   5]] \n",
      "precision: 0.35714285714285715 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.2 \n",
      "auroc: 0.5774999999999999\n",
      "Balanced Accuracy: 0.625 \n",
      "confusion: [[194   6]\n",
      " [ 18   7]] \n",
      "precision: 0.5384615384615384 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.28 \n",
      "auroc: 0.625\n",
      "Balanced Accuracy: 0.6897759103641457 \n",
      "confusion: [[194  10]\n",
      " [ 12   9]] \n",
      "precision: 0.47368421052631576 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.42857142857142855 \n",
      "auroc: 0.6897759103641457\n",
      "Balanced Accuracy: 0.607487922705314 \n",
      "confusion: [[194  13]\n",
      " [ 13   5]] \n",
      "precision: 0.2777777777777778 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.2777777777777778 \n",
      "auroc: 0.6074879227053139\n",
      "Balanced Accuracy: 0.6015258215962441 \n",
      "confusion: [[203  10]\n",
      " [  9   3]] \n",
      "precision: 0.23076923076923078 \n",
      "accuracy: 0.9155555555555556 \n",
      "recall: 0.25 \n",
      "auroc: 0.6015258215962441\n",
      "Balanced Accuracy: 0.530952380952381 \n",
      "confusion: [[195  15]\n",
      " [ 13   2]] \n",
      "precision: 0.11764705882352941 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.13333333333333333 \n",
      "auroc: 0.530952380952381\n",
      "Balanced Accuracy: 0.6209577114427861 \n",
      "confusion: [[191  10]\n",
      " [ 17   7]] \n",
      "precision: 0.4117647058823529 \n",
      "accuracy: 0.88 \n",
      "recall: 0.2916666666666667 \n",
      "auroc: 0.6209577114427861\n",
      "Balanced Accuracy: 0.5448773138183384 \n",
      "confusion: [[185  17]\n",
      " [ 19   4]] \n",
      "precision: 0.19047619047619047 \n",
      "accuracy: 0.84 \n",
      "recall: 0.17391304347826086 \n",
      "auroc: 0.5448773138183383\n",
      "Balanced Accuracy: 0.7101430761369443 \n",
      "confusion: [[195  11]\n",
      " [ 10   9]] \n",
      "precision: 0.45 \n",
      "accuracy: 0.9066666666666666 \n",
      "recall: 0.47368421052631576 \n",
      "auroc: 0.7101430761369443\n",
      "Balanced Accuracy: 0.4891304347826087 \n",
      "confusion: [[191  16]\n",
      " [ 17   1]] \n",
      "precision: 0.058823529411764705 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.05555555555555555 \n",
      "auroc: 0.4891304347826087\n",
      "Balanced Accuracy: 0.6227571770334928 \n",
      "confusion: [[195  14]\n",
      " [ 11   5]] \n",
      "precision: 0.2631578947368421 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.3125 \n",
      "auroc: 0.6227571770334928\n",
      "Balanced Accuracy: 0.6099033816425121 \n",
      "confusion: [[195  12]\n",
      " [ 13   5]] \n",
      "precision: 0.29411764705882354 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.2777777777777778 \n",
      "auroc: 0.609903381642512\n",
      "Balanced Accuracy: 0.5187257856220404 \n",
      "confusion: [[192  10]\n",
      " [ 21   2]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.8622222222222222 \n",
      "recall: 0.08695652173913043 \n",
      "auroc: 0.5187257856220404\n",
      "Balanced Accuracy: 0.5908536585365853 \n",
      "confusion: [[191  14]\n",
      " [ 15   5]] \n",
      "precision: 0.2631578947368421 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.25 \n",
      "auroc: 0.5908536585365853\n",
      "Balanced Accuracy: 0.6182126696832579 \n",
      "confusion: [[196  12]\n",
      " [ 12   5]] \n",
      "precision: 0.29411764705882354 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.29411764705882354 \n",
      "auroc: 0.6182126696832579\n",
      "Balanced Accuracy: 0.538647342995169 \n",
      "confusion: [[200   7]\n",
      " [ 16   2]] \n",
      "precision: 0.2222222222222222 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.1111111111111111 \n",
      "auroc: 0.5386473429951691\n",
      "Balanced Accuracy: 0.5386251679355127 \n",
      "confusion: [[191  12]\n",
      " [ 19   3]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.8622222222222222 \n",
      "recall: 0.13636363636363635 \n",
      "auroc: 0.5386251679355127\n",
      "Balanced Accuracy: 0.7062324929971988 \n",
      "confusion: [[191  13]\n",
      " [ 11  10]] \n",
      "precision: 0.43478260869565216 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.47619047619047616 \n",
      "auroc: 0.7062324929971988\n",
      "Balanced Accuracy: 0.6682926829268293 \n",
      "confusion: [[192  13]\n",
      " [ 12   8]] \n",
      "precision: 0.38095238095238093 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.4 \n",
      "auroc: 0.6682926829268292\n",
      "Balanced Accuracy: 0.5842661691542288 \n",
      "confusion: [[193   8]\n",
      " [ 19   5]] \n",
      "precision: 0.38461538461538464 \n",
      "accuracy: 0.88 \n",
      "recall: 0.20833333333333334 \n",
      "auroc: 0.5842661691542288\n",
      "Balanced Accuracy: 0.6239141543178335 \n",
      "confusion: [[192  14]\n",
      " [ 13   6]] \n",
      "precision: 0.3 \n",
      "accuracy: 0.88 \n",
      "recall: 0.3157894736842105 \n",
      "auroc: 0.6239141543178335\n",
      "Balanced Accuracy: 0.6034688995215312 \n",
      "confusion: [[200   9]\n",
      " [ 12   4]] \n",
      "precision: 0.3076923076923077 \n",
      "accuracy: 0.9066666666666666 \n",
      "recall: 0.25 \n",
      "auroc: 0.6034688995215312\n",
      "Balanced Accuracy: 0.6175204476969436 \n",
      "confusion: [[188  14]\n",
      " [ 16   7]] \n",
      "precision: 0.3333333333333333 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.30434782608695654 \n",
      "auroc: 0.6175204476969436\n",
      "Balanced Accuracy: 0.5564263322884012 \n",
      "confusion: [[189  14]\n",
      " [ 18   4]] \n",
      "precision: 0.2222222222222222 \n",
      "accuracy: 0.8577777777777778 \n",
      "recall: 0.18181818181818182 \n",
      "auroc: 0.5564263322884013\n",
      "Balanced Accuracy: 0.5251865671641791 \n",
      "confusion: [[186  15]\n",
      " [ 21   3]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.84 \n",
      "recall: 0.125 \n",
      "auroc: 0.5251865671641791\n",
      "Balanced Accuracy: 0.5642857142857143 \n",
      "confusion: [[195  15]\n",
      " [ 12   3]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.88 \n",
      "recall: 0.2 \n",
      "auroc: 0.5642857142857143\n",
      "Balanced Accuracy: 0.5554724880382775 \n",
      "confusion: [[193  16]\n",
      " [ 13   3]] \n",
      "precision: 0.15789473684210525 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.1875 \n",
      "auroc: 0.5554724880382775\n",
      "Balanced Accuracy: 0.6319973130317957 \n",
      "confusion: [[192  11]\n",
      " [ 15   7]] \n",
      "precision: 0.3888888888888889 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.3181818181818182 \n",
      "auroc: 0.6319973130317957\n",
      "Balanced Accuracy: 0.5148819421350183 \n",
      "confusion: [[181  13]\n",
      " [ 28   3]] \n",
      "precision: 0.1875 \n",
      "accuracy: 0.8177777777777778 \n",
      "recall: 0.0967741935483871 \n",
      "auroc: 0.5148819421350183\n",
      "Balanced Accuracy: 0.571282575370465 \n",
      "confusion: [[192  14]\n",
      " [ 15   4]] \n",
      "precision: 0.2222222222222222 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.21052631578947367 \n",
      "auroc: 0.571282575370465\n",
      "Balanced Accuracy: 0.5567632850241546 \n",
      "confusion: [[196  11]\n",
      " [ 15   3]] \n",
      "precision: 0.21428571428571427 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.16666666666666666 \n",
      "auroc: 0.5567632850241546\n",
      "Balanced Accuracy: 0.603789592760181 \n",
      "confusion: [[190  18]\n",
      " [ 12   5]] \n",
      "precision: 0.21739130434782608 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.29411764705882354 \n",
      "auroc: 0.603789592760181\n",
      "Balanced Accuracy: 0.5312360053739364 \n",
      "confusion: [[188  15]\n",
      " [ 19   3]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.8488888888888889 \n",
      "recall: 0.13636363636363635 \n",
      "auroc: 0.5312360053739363\n",
      "Balanced Accuracy: 0.6453960731211916 \n",
      "confusion: [[197  14]\n",
      " [  9   5]] \n",
      "precision: 0.2631578947368421 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.35714285714285715 \n",
      "auroc: 0.6453960731211916\n",
      "Balanced Accuracy: 0.5314009661835749 \n",
      "confusion: [[197  10]\n",
      " [ 16   2]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.1111111111111111 \n",
      "auroc: 0.5314009661835749\n",
      "Balanced Accuracy: 0.6749888042991491 \n",
      "confusion: [[191  12]\n",
      " [ 13   9]] \n",
      "precision: 0.42857142857142855 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.4090909090909091 \n",
      "auroc: 0.6749888042991492\n",
      "Balanced Accuracy: 0.6548359728506787 \n",
      "confusion: [[199   9]\n",
      " [ 11   6]] \n",
      "precision: 0.4 \n",
      "accuracy: 0.9111111111111111 \n",
      "recall: 0.35294117647058826 \n",
      "auroc: 0.6548359728506787\n",
      "Balanced Accuracy: 0.5932926829268292 \n",
      "confusion: [[192  13]\n",
      " [ 15   5]] \n",
      "precision: 0.2777777777777778 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.25 \n",
      "auroc: 0.5932926829268292\n",
      "Balanced Accuracy: 0.5797101449275363 \n",
      "confusion: [[194  13]\n",
      " [ 14   4]] \n",
      "precision: 0.23529411764705882 \n",
      "accuracy: 0.88 \n",
      "recall: 0.2222222222222222 \n",
      "auroc: 0.5797101449275363\n",
      "Balanced Accuracy: 0.5521776018099548 \n",
      "confusion: [[193  15]\n",
      " [ 14   3]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.17647058823529413 \n",
      "auroc: 0.5521776018099548\n",
      "Balanced Accuracy: 0.5542717086834734 \n",
      "confusion: [[197   7]\n",
      " [ 18   3]] \n",
      "precision: 0.3 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.14285714285714285 \n",
      "auroc: 0.5542717086834733\n",
      "Balanced Accuracy: 0.6457317073170732 \n",
      "confusion: [[193  12]\n",
      " [ 13   7]] \n",
      "precision: 0.3684210526315789 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.35 \n",
      "auroc: 0.6457317073170732\n",
      "Balanced Accuracy: 0.5658263305322129 \n",
      "confusion: [[192  12]\n",
      " [ 17   4]] \n",
      "precision: 0.25 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.19047619047619047 \n",
      "auroc: 0.5658263305322129\n",
      "Balanced Accuracy: 0.6384146341463415 \n",
      "confusion: [[190  15]\n",
      " [ 13   7]] \n",
      "precision: 0.3181818181818182 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.35 \n",
      "auroc: 0.6384146341463416\n",
      "Balanced Accuracy: 0.5809913132345427 \n",
      "confusion: [[196  10]\n",
      " [ 15   4]] \n",
      "precision: 0.2857142857142857 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.21052631578947367 \n",
      "auroc: 0.5809913132345427\n",
      "Balanced Accuracy: 0.5380952380952381 \n",
      "confusion: [[198  12]\n",
      " [ 13   2]] \n",
      "precision: 0.14285714285714285 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.13333333333333333 \n",
      "auroc: 0.5380952380952381\n",
      "Balanced Accuracy: 0.6066763425253991 \n",
      "confusion: [[192  20]\n",
      " [  9   4]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.3076923076923077 \n",
      "auroc: 0.6066763425253991\n",
      "Balanced Accuracy: 0.5207317073170732 \n",
      "confusion: [[193  12]\n",
      " [ 18   2]] \n",
      "precision: 0.14285714285714285 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.1 \n",
      "auroc: 0.5207317073170732\n",
      "Balanced Accuracy: 0.6384146341463415 \n",
      "confusion: [[190  15]\n",
      " [ 13   7]] \n",
      "precision: 0.3181818181818182 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.35 \n",
      "auroc: 0.6384146341463416\n",
      "Balanced Accuracy: 0.5242224880382775 \n",
      "confusion: [[193  16]\n",
      " [ 14   2]] \n",
      "precision: 0.1111111111111111 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.125 \n",
      "auroc: 0.5242224880382775\n",
      "Balanced Accuracy: 0.605 \n",
      "confusion: [[194   6]\n",
      " [ 19   6]] \n",
      "precision: 0.5 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.24 \n",
      "auroc: 0.605\n",
      "Balanced Accuracy: 0.6809701492537313 \n",
      "confusion: [[190  11]\n",
      " [ 14  10]] \n",
      "precision: 0.47619047619047616 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.4166666666666667 \n",
      "auroc: 0.6809701492537314\n",
      "Balanced Accuracy: 0.5903168114460909 \n",
      "confusion: [[189  17]\n",
      " [ 14   5]] \n",
      "precision: 0.22727272727272727 \n",
      "accuracy: 0.8622222222222222 \n",
      "recall: 0.2631578947368421 \n",
      "auroc: 0.5903168114460909\n",
      "Balanced Accuracy: 0.6741185487991824 \n",
      "confusion: [[191  15]\n",
      " [ 11   8]] \n",
      "precision: 0.34782608695652173 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.42105263157894735 \n",
      "auroc: 0.6741185487991824\n",
      "Balanced Accuracy: 0.5053733031674208 \n",
      "confusion: [[198  10]\n",
      " [ 16   1]] \n",
      "precision: 0.09090909090909091 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.058823529411764705 \n",
      "auroc: 0.5053733031674208\n",
      "Balanced Accuracy: 0.5297619047619048 \n",
      "confusion: [[187  17]\n",
      " [ 18   3]] \n",
      "precision: 0.15 \n",
      "accuracy: 0.8444444444444444 \n",
      "recall: 0.14285714285714285 \n",
      "auroc: 0.5297619047619047\n",
      "Balanced Accuracy: 0.6392595781317263 \n",
      "confusion: [[188  14]\n",
      " [ 15   8]] \n",
      "precision: 0.36363636363636365 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.34782608695652173 \n",
      "auroc: 0.6392595781317262\n",
      "Balanced Accuracy: 0.5787068381855112 \n",
      "confusion: [[199  12]\n",
      " [ 11   3]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.21428571428571427 \n",
      "auroc: 0.578706838185511\n",
      "Balanced Accuracy: 0.5035014005602241 \n",
      "confusion: [[186  18]\n",
      " [ 19   2]] \n",
      "precision: 0.1 \n",
      "accuracy: 0.8355555555555556 \n",
      "recall: 0.09523809523809523 \n",
      "auroc: 0.5035014005602242\n",
      "Balanced Accuracy: 0.6293585880327164 \n",
      "confusion: [[184  18]\n",
      " [ 15   8]] \n",
      "precision: 0.3076923076923077 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.34782608695652173 \n",
      "auroc: 0.6293585880327163\n",
      "Balanced Accuracy: 0.6295342588446037 \n",
      "confusion: [[191  12]\n",
      " [ 15   7]] \n",
      "precision: 0.3684210526315789 \n",
      "accuracy: 0.88 \n",
      "recall: 0.3181818181818182 \n",
      "auroc: 0.6295342588446037\n",
      "Balanced Accuracy: 0.6442100731812311 \n",
      "confusion: [[190  12]\n",
      " [ 15   8]] \n",
      "precision: 0.4 \n",
      "accuracy: 0.88 \n",
      "recall: 0.34782608695652173 \n",
      "auroc: 0.6442100731812311\n",
      "Balanced Accuracy: 0.522887323943662 \n",
      "confusion: [[205   8]\n",
      " [ 11   1]] \n",
      "precision: 0.1111111111111111 \n",
      "accuracy: 0.9155555555555556 \n",
      "recall: 0.08333333333333333 \n",
      "auroc: 0.522887323943662\n",
      "Balanced Accuracy: 0.5477318889641164 \n",
      "confusion: [[201  10]\n",
      " [ 12   2]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.14285714285714285 \n",
      "auroc: 0.5477318889641164\n",
      "Balanced Accuracy: 0.542016806722689 \n",
      "confusion: [[192  12]\n",
      " [ 18   3]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.14285714285714285 \n",
      "auroc: 0.542016806722689\n",
      "Balanced Accuracy: 0.5518207282913166 \n",
      "confusion: [[196   8]\n",
      " [ 18   3]] \n",
      "precision: 0.2727272727272727 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.14285714285714285 \n",
      "auroc: 0.5518207282913165\n",
      "Balanced Accuracy: 0.6166326009197751 \n",
      "confusion: [[189  17]\n",
      " [ 13   6]] \n",
      "precision: 0.2608695652173913 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.3157894736842105 \n",
      "auroc: 0.6166326009197752\n",
      "Balanced Accuracy: 0.5333333333333333 \n",
      "confusion: [[196  14]\n",
      " [ 13   2]] \n",
      "precision: 0.125 \n",
      "accuracy: 0.88 \n",
      "recall: 0.13333333333333333 \n",
      "auroc: 0.5333333333333333\n",
      "Balanced Accuracy: 0.5933060697374085 \n",
      "confusion: [[187  15]\n",
      " [ 17   6]] \n",
      "precision: 0.2857142857142857 \n",
      "accuracy: 0.8577777777777778 \n",
      "recall: 0.2608695652173913 \n",
      "auroc: 0.5933060697374085\n",
      "Balanced Accuracy: 0.5772946859903382 \n",
      "confusion: [[193  14]\n",
      " [ 14   4]] \n",
      "precision: 0.2222222222222222 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.2222222222222222 \n",
      "auroc: 0.5772946859903383\n",
      "Balanced Accuracy: 0.5903168114460909 \n",
      "confusion: [[189  17]\n",
      " [ 14   5]] \n",
      "precision: 0.22727272727272727 \n",
      "accuracy: 0.8622222222222222 \n",
      "recall: 0.2631578947368421 \n",
      "auroc: 0.5903168114460909\n",
      "Balanced Accuracy: 0.5695701357466063 \n",
      "confusion: [[188  20]\n",
      " [ 13   4]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.23529411764705882 \n",
      "auroc: 0.5695701357466063\n",
      "Balanced Accuracy: 0.6106459330143541 \n",
      "confusion: [[203   6]\n",
      " [ 12   4]] \n",
      "precision: 0.4 \n",
      "accuracy: 0.92 \n",
      "recall: 0.25 \n",
      "auroc: 0.610645933014354\n",
      "Balanced Accuracy: 0.5578648325358851 \n",
      "confusion: [[194  15]\n",
      " [ 13   3]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.1875 \n",
      "auroc: 0.5578648325358851\n",
      "Balanced Accuracy: 0.5908536585365853 \n",
      "confusion: [[191  14]\n",
      " [ 15   5]] \n",
      "precision: 0.2631578947368421 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.25 \n",
      "auroc: 0.5908536585365853\n",
      "Balanced Accuracy: 0.6299019607843137 \n",
      "confusion: [[189  15]\n",
      " [ 14   7]] \n",
      "precision: 0.3181818181818182 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.6299019607843137\n",
      "Balanced Accuracy: 0.6261904761904762 \n",
      "confusion: [[193  17]\n",
      " [ 10   5]] \n",
      "precision: 0.22727272727272727 \n",
      "accuracy: 0.88 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.6261904761904761\n",
      "Balanced Accuracy: 0.642512077294686 \n",
      "confusion: [[197  10]\n",
      " [ 12   6]] \n",
      "precision: 0.375 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.642512077294686\n",
      "Balanced Accuracy: 0.5934343434343434 \n",
      "confusion: [[191   7]\n",
      " [ 21   6]] \n",
      "precision: 0.46153846153846156 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.2222222222222222 \n",
      "auroc: 0.5934343434343435\n",
      "Balanced Accuracy: 0.6569303338171263 \n",
      "confusion: [[197  15]\n",
      " [  8   5]] \n",
      "precision: 0.25 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.38461538461538464 \n",
      "auroc: 0.6569303338171263\n",
      "Balanced Accuracy: 0.5523030563925958 \n",
      "confusion: [[188  14]\n",
      " [ 19   4]] \n",
      "precision: 0.2222222222222222 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.17391304347826086 \n",
      "auroc: 0.5523030563925957\n",
      "Balanced Accuracy: 0.5441801189464741 \n",
      "confusion: [[194  20]\n",
      " [  9   2]] \n",
      "precision: 0.09090909090909091 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.18181818181818182 \n",
      "auroc: 0.5441801189464741\n",
      "Balanced Accuracy: 0.6834800270819228 \n",
      "confusion: [[198  13]\n",
      " [  8   6]] \n",
      "precision: 0.3157894736842105 \n",
      "accuracy: 0.9066666666666666 \n",
      "recall: 0.42857142857142855 \n",
      "auroc: 0.6834800270819229\n",
      "Balanced Accuracy: 0.6060975609756097 \n",
      "confusion: [[187  18]\n",
      " [ 14   6]] \n",
      "precision: 0.25 \n",
      "accuracy: 0.8577777777777778 \n",
      "recall: 0.3 \n",
      "auroc: 0.6060975609756099\n",
      "Balanced Accuracy: 0.6778169014084507 \n",
      "confusion: [[200  13]\n",
      " [  7   5]] \n",
      "precision: 0.2777777777777778 \n",
      "accuracy: 0.9111111111111111 \n",
      "recall: 0.4166666666666667 \n",
      "auroc: 0.6778169014084507\n",
      "Balanced Accuracy: 0.5169082125603864 \n",
      "confusion: [[191  16]\n",
      " [ 16   2]] \n",
      "precision: 0.1111111111111111 \n",
      "accuracy: 0.8577777777777778 \n",
      "recall: 0.1111111111111111 \n",
      "auroc: 0.5169082125603865\n",
      "Balanced Accuracy: 0.5662785490371697 \n",
      "confusion: [[193  10]\n",
      " [ 18   4]] \n",
      "precision: 0.2857142857142857 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.18181818181818182 \n",
      "auroc: 0.5662785490371698\n",
      "Balanced Accuracy: 0.6257002801120448 \n",
      "confusion: [[197   7]\n",
      " [ 15   6]] \n",
      "precision: 0.46153846153846156 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.2857142857142857 \n",
      "auroc: 0.6257002801120447\n",
      "Balanced Accuracy: 0.6882193635748138 \n",
      "confusion: [[200  11]\n",
      " [  8   6]] \n",
      "precision: 0.35294117647058826 \n",
      "accuracy: 0.9155555555555556 \n",
      "recall: 0.42857142857142855 \n",
      "auroc: 0.6882193635748138\n",
      "Balanced Accuracy: 0.6220657276995305 \n",
      "confusion: [[194  19]\n",
      " [  8   4]] \n",
      "precision: 0.17391304347826086 \n",
      "accuracy: 0.88 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.6220657276995305\n",
      "Balanced Accuracy: 0.6376811594202898 \n",
      "confusion: [[195  12]\n",
      " [ 12   6]] \n",
      "precision: 0.3333333333333333 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.6376811594202898\n",
      "Balanced Accuracy: 0.62 \n",
      "confusion: [[192   8]\n",
      " [ 18   7]] \n",
      "precision: 0.4666666666666667 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.28 \n",
      "auroc: 0.62\n",
      "Balanced Accuracy: 0.6395035885167464 \n",
      "confusion: [[202   7]\n",
      " [ 11   5]] \n",
      "precision: 0.4166666666666667 \n",
      "accuracy: 0.92 \n",
      "recall: 0.3125 \n",
      "auroc: 0.6395035885167465\n",
      "Balanced Accuracy: 0.5809913132345427 \n",
      "confusion: [[196  10]\n",
      " [ 15   4]] \n",
      "precision: 0.2857142857142857 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.21052631578947367 \n",
      "auroc: 0.5809913132345427\n",
      "Balanced Accuracy: 0.6384146341463415 \n",
      "confusion: [[190  15]\n",
      " [ 13   7]] \n",
      "precision: 0.3181818181818182 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.35 \n",
      "auroc: 0.6384146341463416\n",
      "Balanced Accuracy: 0.6574136763710223 \n",
      "confusion: [[187  24]\n",
      " [  8   6]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.8577777777777778 \n",
      "recall: 0.42857142857142855 \n",
      "auroc: 0.6574136763710224\n",
      "Balanced Accuracy: 0.5888009049773756 \n",
      "confusion: [[196  12]\n",
      " [ 13   4]] \n",
      "precision: 0.25 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.23529411764705882 \n",
      "auroc: 0.5888009049773756\n",
      "Balanced Accuracy: 0.6085434173669468 \n",
      "confusion: [[190  14]\n",
      " [ 15   6]] \n",
      "precision: 0.3 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.2857142857142857 \n",
      "auroc: 0.6085434173669467\n",
      "Balanced Accuracy: 0.659643665158371 \n",
      "confusion: [[201   7]\n",
      " [ 11   6]] \n",
      "precision: 0.46153846153846156 \n",
      "accuracy: 0.92 \n",
      "recall: 0.35294117647058826 \n",
      "auroc: 0.659643665158371\n",
      "Balanced Accuracy: 0.6174999999999999 \n",
      "confusion: [[191   9]\n",
      " [ 18   7]] \n",
      "precision: 0.4375 \n",
      "accuracy: 0.88 \n",
      "recall: 0.28 \n",
      "auroc: 0.6174999999999999\n",
      "Balanced Accuracy: 0.6620475113122172 \n",
      "confusion: [[202   6]\n",
      " [ 11   6]] \n",
      "precision: 0.5 \n",
      "accuracy: 0.9244444444444444 \n",
      "recall: 0.35294117647058826 \n",
      "auroc: 0.6620475113122172\n",
      "Balanced Accuracy: 0.6481707317073171 \n",
      "confusion: [[194  11]\n",
      " [ 13   7]] \n",
      "precision: 0.3888888888888889 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.35 \n",
      "auroc: 0.6481707317073171\n",
      "Balanced Accuracy: 0.6536585365853659 \n",
      "confusion: [[186  19]\n",
      " [ 12   8]] \n",
      "precision: 0.2962962962962963 \n",
      "accuracy: 0.8622222222222222 \n",
      "recall: 0.4 \n",
      "auroc: 0.6536585365853659\n",
      "Balanced Accuracy: 0.532381221719457 \n",
      "confusion: [[197  11]\n",
      " [ 15   2]] \n",
      "precision: 0.15384615384615385 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.11764705882352941 \n",
      "auroc: 0.532381221719457\n",
      "Balanced Accuracy: 0.6219806763285024 \n",
      "confusion: [[200   7]\n",
      " [ 13   5]] \n",
      "precision: 0.4166666666666667 \n",
      "accuracy: 0.9111111111111111 \n",
      "recall: 0.2777777777777778 \n",
      "auroc: 0.6219806763285024\n",
      "Balanced Accuracy: 0.5658263305322129 \n",
      "confusion: [[192  12]\n",
      " [ 17   4]] \n",
      "precision: 0.25 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.19047619047619047 \n",
      "auroc: 0.5658263305322129\n",
      "Balanced Accuracy: 0.5072782667569398 \n",
      "confusion: [[199  12]\n",
      " [ 13   1]] \n",
      "precision: 0.07692307692307693 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.07142857142857142 \n",
      "auroc: 0.5072782667569397\n",
      "Balanced Accuracy: 0.5617929864253394 \n",
      "confusion: [[197  11]\n",
      " [ 14   3]] \n",
      "precision: 0.21428571428571427 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.17647058823529413 \n",
      "auroc: 0.5617929864253394\n",
      "Balanced Accuracy: 0.6318407960199005 \n",
      "confusion: [[187  14]\n",
      " [ 16   8]] \n",
      "precision: 0.36363636363636365 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.6318407960199004\n",
      "Balanced Accuracy: 0.6304347826086957 \n",
      "confusion: [[192  15]\n",
      " [ 12   6]] \n",
      "precision: 0.2857142857142857 \n",
      "accuracy: 0.88 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.6304347826086957\n",
      "Balanced Accuracy: 0.6774518584863413 \n",
      "confusion: [[192  11]\n",
      " [ 13   9]] \n",
      "precision: 0.45 \n",
      "accuracy: 0.8933333333333333 \n",
      "recall: 0.4090909090909091 \n",
      "auroc: 0.6774518584863413\n",
      "Balanced Accuracy: 0.5845410628019323 \n",
      "confusion: [[196  11]\n",
      " [ 14   4]] \n",
      "precision: 0.26666666666666666 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.2222222222222222 \n",
      "auroc: 0.5845410628019324\n",
      "Balanced Accuracy: 0.642816742081448 \n",
      "confusion: [[194  14]\n",
      " [ 11   6]] \n",
      "precision: 0.3 \n",
      "accuracy: 0.8888888888888888 \n",
      "recall: 0.35294117647058826 \n",
      "auroc: 0.642816742081448\n",
      "Balanced Accuracy: 0.6158536585365854 \n",
      "confusion: [[191  14]\n",
      " [ 14   6]] \n",
      "precision: 0.3 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.3 \n",
      "auroc: 0.6158536585365854\n",
      "Balanced Accuracy: 0.5125848416289592 \n",
      "confusion: [[201   7]\n",
      " [ 16   1]] \n",
      "precision: 0.125 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.058823529411764705 \n",
      "auroc: 0.5125848416289592\n",
      "Balanced Accuracy: 0.580532212885154 \n",
      "confusion: [[198   6]\n",
      " [ 17   4]] \n",
      "precision: 0.4 \n",
      "accuracy: 0.8977777777777778 \n",
      "recall: 0.19047619047619047 \n",
      "auroc: 0.580532212885154\n",
      "Balanced Accuracy: 0.5259325498211549 \n",
      "confusion: [[195  11]\n",
      " [ 17   2]] \n",
      "precision: 0.15384615384615385 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.10526315789473684 \n",
      "auroc: 0.5259325498211548\n",
      "Balanced Accuracy: 0.5883547731888964 \n",
      "confusion: [[188  23]\n",
      " [ 10   4]] \n",
      "precision: 0.14814814814814814 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.2857142857142857 \n",
      "auroc: 0.5883547731888963\n",
      "Balanced Accuracy: 0.6350201522615315 \n",
      "confusion: [[184  19]\n",
      " [ 14   8]] \n",
      "precision: 0.2962962962962963 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.36363636363636365 \n",
      "auroc: 0.6350201522615316\n",
      "Balanced Accuracy: 0.5567632850241546 \n",
      "confusion: [[196  11]\n",
      " [ 15   3]] \n",
      "precision: 0.21428571428571427 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.16666666666666666 \n",
      "auroc: 0.5567632850241546\n",
      "Balanced Accuracy: 0.6134453781512605 \n",
      "confusion: [[192  12]\n",
      " [ 15   6]] \n",
      "precision: 0.3333333333333333 \n",
      "accuracy: 0.88 \n",
      "recall: 0.2857142857142857 \n",
      "auroc: 0.6134453781512604\n",
      "Balanced Accuracy: 0.520658263305322 \n",
      "confusion: [[193  11]\n",
      " [ 19   2]] \n",
      "precision: 0.15384615384615385 \n",
      "accuracy: 0.8666666666666667 \n",
      "recall: 0.09523809523809523 \n",
      "auroc: 0.5206582633053222\n",
      "Balanced Accuracy: 0.5915071770334928 \n",
      "confusion: [[195  14]\n",
      " [ 12   4]] \n",
      "precision: 0.2222222222222222 \n",
      "accuracy: 0.8844444444444445 \n",
      "recall: 0.25 \n",
      "auroc: 0.5915071770334929\n",
      "Balanced Accuracy: 0.6304347826086957 \n",
      "confusion: [[192  15]\n",
      " [ 12   6]] \n",
      "precision: 0.2857142857142857 \n",
      "accuracy: 0.88 \n",
      "recall: 0.3333333333333333 \n",
      "auroc: 0.6304347826086957\n",
      "Balanced Accuracy: 0.6102693602693603 \n",
      "confusion: [[183  15]\n",
      " [ 19   8]] \n",
      "precision: 0.34782608695652173 \n",
      "accuracy: 0.8488888888888889 \n",
      "recall: 0.2962962962962963 \n",
      "auroc: 0.6102693602693602\n",
      "Balanced Accuracy: 0.5478906586310804 \n",
      "confusion: [[195   7]\n",
      " [ 20   3]] \n",
      "precision: 0.3 \n",
      "accuracy: 0.88 \n",
      "recall: 0.13043478260869565 \n",
      "auroc: 0.5478906586310804\n",
      "Balanced Accuracy: 0.7517605633802817 \n",
      "confusion: [[196  17]\n",
      " [  5   7]] \n",
      "precision: 0.2916666666666667 \n",
      "accuracy: 0.9022222222222223 \n",
      "recall: 0.5833333333333334 \n",
      "auroc: 0.7517605633802817\n",
      "Balanced Accuracy: 0.6734397677793904 \n",
      "confusion: [[204   8]\n",
      " [  8   5]] \n",
      "precision: 0.38461538461538464 \n",
      "accuracy: 0.9288888888888889 \n",
      "recall: 0.38461538461538464 \n",
      "auroc: 0.6734397677793904\n",
      "Balanced Accuracy: 0.6384146341463415 \n",
      "confusion: [[190  15]\n",
      " [ 13   7]] \n",
      "precision: 0.3181818181818182 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.35 \n",
      "auroc: 0.6384146341463416\n",
      "Balanced Accuracy: 0.5584733893557423 \n",
      "confusion: [[189  15]\n",
      " [ 17   4]] \n",
      "precision: 0.21052631578947367 \n",
      "accuracy: 0.8577777777777778 \n",
      "recall: 0.19047619047619047 \n",
      "auroc: 0.5584733893557423\n",
      "Balanced Accuracy: 0.6358830845771144 \n",
      "confusion: [[197   4]\n",
      " [ 17   7]] \n",
      "precision: 0.6363636363636364 \n",
      "accuracy: 0.9066666666666666 \n",
      "recall: 0.2916666666666667 \n",
      "auroc: 0.6358830845771145\n",
      "Balanced Accuracy: 0.5975983648441492 \n",
      "confusion: [[192  14]\n",
      " [ 14   5]] \n",
      "precision: 0.2631578947368421 \n",
      "accuracy: 0.8755555555555555 \n",
      "recall: 0.2631578947368421 \n",
      "auroc: 0.5975983648441492\n",
      "Balanced Accuracy: 0.5543478260869565 \n",
      "confusion: [[195  12]\n",
      " [ 15   3]] \n",
      "precision: 0.2 \n",
      "accuracy: 0.88 \n",
      "recall: 0.16666666666666666 \n",
      "auroc: 0.5543478260869565\n",
      "Balanced Accuracy: 0.5893892539621183 \n",
      "confusion: [[181  18]\n",
      " [ 19   7]] \n",
      "precision: 0.28 \n",
      "accuracy: 0.8355555555555556 \n",
      "recall: 0.2692307692307692 \n",
      "auroc: 0.5893892539621183\n",
      "Balanced Accuracy: 0.5660030923850019 \n",
      "confusion: [[187  12]\n",
      " [ 21   5]] \n",
      "precision: 0.29411764705882354 \n",
      "accuracy: 0.8533333333333334 \n",
      "recall: 0.19230769230769232 \n",
      "auroc: 0.5660030923850019\n",
      "Balanced Accuracy: 0.5904761904761905 \n",
      "confusion: [[192  18]\n",
      " [ 11   4]] \n",
      "precision: 0.18181818181818182 \n",
      "accuracy: 0.8711111111111111 \n",
      "recall: 0.26666666666666666 \n",
      "auroc: 0.5904761904761905\n",
      "Balanced Accuracy: 0.5642857142857143 \n",
      "confusion: [[195  15]\n",
      " [ 12   3]] \n",
      "precision: 0.16666666666666666 \n",
      "accuracy: 0.88 \n",
      "recall: 0.2 \n",
      "auroc: 0.5642857142857143\n",
      "0.5934256075029839\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"n_estimators\":study.best_trial.params['n_estimators'],\n",
    "        \"learning_rate\": study.best_trial.params['learning_rate'],\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": study.best_trial.params['lambda_l1'],\n",
    "        \"lambda_l2\": study.best_trial.params['lambda_l2'] ,\n",
    "        \"num_leaves\": study.best_trial.params['num_leaves'],\n",
    "        \"feature_fraction\": study.best_trial.params['feature_fraction'],\n",
    "        \"bagging_fraction\": study.best_trial.params['bagging_fraction'],\n",
    "        \"bagging_freq\": study.best_trial.params['bagging_freq'],\n",
    "        \"min_child_samples\": study.best_trial.params['min_child_samples'],\n",
    "    }\n",
    "\n",
    "lst = []\n",
    "for i in range(200):\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(drugs.loc[:,drugs.columns!='consumption_cocaine_last_month'], drugs.consumption_cocaine_last_month, test_size=0.15, random_state = i+1*11)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "    gbm = lgb.train(param, dtrain)\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.where(preds>0.4,1,0)\n",
    "    lst.append(balanced_accuracy_score(valid_y, pred_labels))\n",
    "\n",
    "    our_metrics(valid_y, pred_labels)\n",
    "print(np.mean(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.572463768115942 \n",
      "confusion: [[135   3]\n",
      " [ 10   2]] \n",
      "precision: 0.4 \n",
      "accuracy: 0.9133333333333333 \n",
      "recall: 0.16666666666666666 \n",
      "auroc: 0.5724637681159421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(drugs.loc[:,drugs.columns!='consumption_cocaine_last_month'], drugs.consumption_cocaine_last_month, test_size=0.1, random_state = 997)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "knn_pred = knn.predict(valid_x)\n",
    "\n",
    "our_metrics(valid_y, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.6-cp39-none-win_amd64.whl (73.9 MB)\n",
      "     ---------------------------------------- 73.9/73.9 MB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\leski\\appdata\\roaming\\python\\python39\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from catboost) (0.19.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from catboost) (1.8.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.8.0-py2.py3-none-any.whl (15.2 MB)\n",
      "     ---------------------------------------- 15.2/15.2 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from catboost) (1.22.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\leski\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->catboost) (4.31.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->catboost) (1.4.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\leski\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->catboost) (3.0.7)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, catboost\n",
      "Successfully installed catboost-1.0.6 plotly-5.8.0 tenacity-8.0.1\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install catboost"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12080277744b494a6e3c186da3e912450d69eab61bfdf7b06084b016002dc5c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
